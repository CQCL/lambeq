<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lambeq.training.pytorch_trainer &mdash; lambeq 0.2.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> lambeq
            <img src="../../../_static/lambeq_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../parsing.html">Syntactic parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../string_diagrams.html">String diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../discopy.html">DisCoPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CONTRIBUTING.html">Contributing to lambeq</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/sentence-input.html">Step 1. Sentence input</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/rewrite.html">Step 2. Diagram rewriting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/parameterise.html">Step 3. Parameterisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Step 4: Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../manual_training.html">Advanced: Manual training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced.html">Advanced: DisCoPy usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/extend-lambeq.html">Advanced: Extending lambeq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Toolkit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../root-api.html">lambeq package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../package-api.html">Subpackages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-line interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../release_notes.html">Release notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">External links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/downloads.html">Resources</a></li>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/generate.html">Web demo</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discopy.readthedocs.io">DisCoPy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">lambeq</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>lambeq.training.pytorch_trainer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for lambeq.training.pytorch_trainer</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2021, 2022 Cambridge Quantum Computing Ltd.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">PytorchTrainer</span>
<span class="sd">==============</span>
<span class="sd">A trainer that wraps the training loop of a :py:class:`ClassicalModel`.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">lambeq.core.globals</span> <span class="kn">import</span> <span class="n">VerbosityLevel</span>
<span class="kn">from</span> <span class="nn">lambeq.training.pytorch_model</span> <span class="kn">import</span> <span class="n">PytorchModel</span>
<span class="kn">from</span> <span class="nn">lambeq.training.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>


<div class="viewcode-block" id="PytorchTrainer"><a class="viewcode-back" href="../../../root-api.html#lambeq.training.PytorchTrainer">[docs]</a><span class="k">class</span> <span class="nc">PytorchTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A PyTorch trainer for the classical pipeline.&quot;&quot;&quot;</span>

    <span class="n">model</span><span class="p">:</span> <span class="n">PytorchModel</span>

<div class="viewcode-block" id="PytorchTrainer.__init__"><a class="viewcode-back" href="../../../root-api.html#lambeq.training.PytorchTrainer.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">model</span><span class="p">:</span> <span class="n">PytorchModel</span><span class="p">,</span>
            <span class="n">loss_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
            <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
            <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">evaluate_functions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">evaluate_on_train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">use_tensorboard</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">log_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">from_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">verbose</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">VerbosityLevel</span><span class="o">.</span><span class="n">TEXT</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initialise a :py:class:`.Trainer` instance using the PyTorch</span>
<span class="sd">        backend.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : :py:class:`.PytorchModel`</span>
<span class="sd">            A lambeq Model using the PyTorch backend for tensor computation.</span>
<span class="sd">        loss_function : callable</span>
<span class="sd">            A PyTorch loss function from `torch.nn`.</span>
<span class="sd">        optimizer : torch.optim.Optimizer, default: torch.optim.AdamW</span>
<span class="sd">            A PyTorch optimizer from `torch.optim`.</span>
<span class="sd">        learning_rate : float, default: 1e-3</span>
<span class="sd">            The learning rate for training.</span>
<span class="sd">        epochs : int</span>
<span class="sd">            Number of training epochs.</span>
<span class="sd">        device : int, default: -1</span>
<span class="sd">            CUDA device ID used for tensor operation speed-up. A negative value</span>
<span class="sd">            uses the CPU.</span>
<span class="sd">        evaluate_functions : mapping of str to callable, optional</span>
<span class="sd">            Mapping of evaluation metric functions from their names.</span>
<span class="sd">            Structure [{\&quot;metric\&quot;: func}].</span>
<span class="sd">            Each function takes the prediction \&quot;y_hat\&quot; and the label \&quot;y\&quot; as</span>
<span class="sd">            input.</span>
<span class="sd">            The validation step calls \&quot;func(y_hat, y)\&quot;.</span>
<span class="sd">        evaluate_on_train : bool, default: True</span>
<span class="sd">            Evaluate the metrics on the train dataset.</span>
<span class="sd">        use_tensorboard : bool, default: False</span>
<span class="sd">            Use Tensorboard for visualisation of the training logs.</span>
<span class="sd">        log_dir : str or PathLike, optional</span>
<span class="sd">            Location of model checkpoints (and tensorboard log). Default is</span>
<span class="sd">            `runs/**CURRENT_DATETIME_HOSTNAME**`.</span>
<span class="sd">        from_checkpoint : bool, default: False</span>
<span class="sd">            Starts training from the checkpoint, saved in the log_dir.</span>
<span class="sd">        verbose : str, default: &#39;text&#39;,</span>
<span class="sd">            See :py:class:`VerbosityLevel` for options.</span>
<span class="sd">        seed : int, optional</span>
<span class="sd">            Random seed.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                         <span class="n">loss_function</span><span class="p">,</span>
                         <span class="n">epochs</span><span class="p">,</span>
                         <span class="n">evaluate_functions</span><span class="p">,</span>
                         <span class="n">evaluate_on_train</span><span class="p">,</span>
                         <span class="n">use_tensorboard</span><span class="p">,</span>
                         <span class="n">log_dir</span><span class="p">,</span>
                         <span class="n">from_checkpoint</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="p">,</span>
                         <span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="s1">&#39;pytorch&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span> <span class="k">if</span> <span class="n">device</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">(</span><span class="s1">&#39;torch.cuda.FloatTensor&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>  <span class="c1"># type: ignore</span>
                                   <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>   <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_add_extra_chkpoint_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Add any additional information to the training checkpoint. These</span>
<span class="sd">        might include model-specific information like the random state of the</span>
<span class="sd">        backend or the state of the optimizer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Mapping of str to any</span>
<span class="sd">            Mapping containing the extra information to save.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;torch_random_state&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">(),</span>
                <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">_load_extra_chkpoint_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Load the additional checkpoint information that was previously</span>
<span class="sd">        added by calling the method `_add_extra_chkpoint_info()`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        checkpoint : Mapping of str to any</span>
<span class="sd">            Mapping containing the checkpoint information.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;torch_random_state&#39;</span><span class="p">])</span>

<div class="viewcode-block" id="PytorchTrainer.validation_step"><a class="viewcode-back" href="../../../root-api.html#lambeq.training.PytorchTrainer.validation_step">[docs]</a>    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                                            <span class="nb">float</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Perform a validation step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch : tuple of list and torch.Tensor</span>
<span class="sd">            Current batch.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple of torch.Tensor and float</span>
<span class="sd">            The model predictions and the calculated loss.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span></div>

<div class="viewcode-block" id="PytorchTrainer.training_step"><a class="viewcode-back" href="../../../root-api.html#lambeq.training.PytorchTrainer.training_step">[docs]</a>    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                                            <span class="nb">float</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Perform a training step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch : tuple of list and torch.Tensor</span>
<span class="sd">            Current batch.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The calculated loss.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, 2022, Cambridge Quantum Computing Ltd..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>