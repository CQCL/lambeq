<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lambeq.bobcat &mdash; lambeq 0.4.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/table-wrap.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            lambeq
              <img src="_static/lambeq_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.4.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="parsing.html">Syntactic parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="string-diagrams.html">String diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="use-cases.html">lambeq use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributing to lambeq</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NLP-101</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="nlp-intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-data.html">Working with text data</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-class.html">Text classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-ml.html">Machine learning best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-refs.html">References for further study</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/sentence-input.html">Step 1. Sentence input</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/rewrite.html">Step 2. Diagram rewriting</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/parameterise.html">Step 3. Parameterisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Step 4: Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Choosing a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="manual-training.html">Advanced: Manual training</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced.html">Advanced: low-level lambeq</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/extend-lambeq.html">Advanced: Extending lambeq</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Toolkit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="root-api.html">lambeq package</a></li>
<li class="toctree-l1"><a class="reference internal" href="package-api.html">Subpackages</a></li>
<li class="toctree-l1"><a class="reference internal" href="uml-diagrams.html">Class diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command-line interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="release-notes.html">Release notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">External links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/downloads.html">Resources</a></li>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/generate.html">Web demo</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discopy.readthedocs.io">DisCoPy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">lambeq</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">lambeq.bobcat</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/CQCL/lambeq/blob/main/docs/lambeq.bobcat.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="module-lambeq.bobcat">
<span id="lambeq-bobcat"></span><h1>lambeq.bobcat<a class="headerlink" href="#module-lambeq.bobcat" title="Permalink to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">BertForChartClassification</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ChartClassifierConfig</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#BertForChartClassification"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BertPreTrainedModel</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">~T_destination</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.T_destination" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Call self as a function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ChartClassifierConfig</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#BertForChartClassification.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.active_adapter">
<span class="sig-name descname"><span class="pre">active_adapter</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.active_adapter" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.active_adapters">
<span class="sig-name descname"><span class="pre">active_adapters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.active_adapters" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Gets the current active adapters of the model. In case of multi-adapter inference (combining multiple adapters
for inference) returns the list of all active adapters so that users can deal with them accordingly.</p>
<p>For previous PEFT versions (that does not support multi-adapter inference), <cite>module.active_adapter</cite> will return
a single string.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.add_adapter">
<span class="sig-name descname"><span class="pre">add_adapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adapter_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.add_adapter" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Adds a fresh new adapter to the current model for training purpose. If no adapter name is passed, a default
name is assigned to the adapter to follow the convention of PEFT library (in PEFT we use “default” as the
default adapter name).</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>adapter_config (<cite>~peft.PeftConfig</cite>):</dt><dd><p>The configuration of the adapter to add, supported adapters are non-prefix tuning and adaption prompts
methods</p>
</dd>
<dt>adapter_name (<cite>str</cite>, <em>optional</em>, defaults to <cite>“default”</cite>):</dt><dd><p>The name of the adapter to add. If no name is passed, a default name is assigned to the adapter.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.add_memory_hooks">
<span class="sig-name descname"><span class="pre">add_memory_hooks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.add_memory_hooks" title="Permalink to this definition"></a></dt>
<dd><p>Add a memory hook before and after each sub-module forward pass to record increase in memory consumption.</p>
<p>Increase in memory consumption is stored in a <cite>mem_rss_diff</cite> attribute for each module and can be reset to zero
with <cite>model.reset_memory_hooks_state()</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.add_model_tags">
<span class="sig-name descname"><span class="pre">add_model_tags</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.add_model_tags" title="Permalink to this definition"></a></dt>
<dd><p>Add custom tags into the model that gets pushed to the Hugging Face Hub. Will
not overwrite existing tags in the model.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>tags (<cite>Union[List[str], str]</cite>):</dt><dd><p>The desired tags to inject in the model</p>
</dd>
</dl>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
from transformers import AutoModel</p>
<p>model = AutoModel.from_pretrained(“google-bert/bert-base-cased”)</p>
<p>model.add_model_tags([“custom”, “custom-bert”])</p>
<p># Push the model to your namespace with the name “my-custom-bert”.
model.push_to_hub(“my-custom-bert”)
<a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.add_module" title="Permalink to this definition"></a></dt>
<dd><p>Add a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>name (str): name of the child module. The child module can be</dt><dd><p>accessed from this module using the given name</p>
</dd>
</dl>
<p>module (Module): child module to be added to the module.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.apply" title="Permalink to this definition"></a></dt>
<dd><p>Apply <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p>
<p>Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None): function to be applied to each submodule</p>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.assisted_decoding">
<span class="sig-name descname"><span class="pre">assisted_decoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.assisted_decoding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.base_model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Module</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.base_model" title="Permalink to this definition"></a></dt>
<dd><p><cite>torch.nn.Module</cite>: The main body of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.base_model_prefix">
<span class="sig-name descname"><span class="pre">base_model_prefix</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'bert'</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.base_model_prefix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.beam_sample">
<span class="sig-name descname"><span class="pre">beam_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.beam_sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.beam_search">
<span class="sig-name descname"><span class="pre">beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.beam_search" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.bfloat16" title="Permalink to this definition"></a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.buffers" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over module buffers.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>recurse (bool): if True, then yields buffers of this module</dt><dd><p>and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
</dl>
</dd>
<dt>Yields:</dt><dd><p>torch.Tensor: module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.call_super_init" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.can_generate">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">can_generate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.can_generate" title="Permalink to this definition"></a></dt>
<dd><p>Returns whether this model can generate sequences with <cite>.generate()</cite>.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p><cite>bool</cite>: Whether this model can generate sequences with <cite>.generate()</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.children" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over immediate children modules.</p>
<dl class="simple">
<dt>Yields:</dt><dd><p>Module: a child module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.compile" title="Permalink to this definition"></a></dt>
<dd><p>Compile this Module’s forward using <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>This Module’s <cite>__call__</cite> method is compiled and all arguments are passed as-is
to <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code>.</p>
<p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.compute_transition_scores">
<span class="sig-name descname"><span class="pre">compute_transition_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_logits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.compute_transition_scores" title="Permalink to this definition"></a></dt>
<dd><p>Computes the transition scores of sequences given the generation scores (and beam indices, if beam search was
used). This is a convenient method to quicky obtain the scores of the selected tokens at generation time.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><dl class="simple">
<dt>sequences (<cite>torch.LongTensor</cite>):</dt><dd><p>The generated sequences. The second dimension (sequence_length) is either equal to <cite>max_length</cite> or
shorter if all batches finished early due to the <cite>eos_token_id</cite>.</p>
</dd>
<dt>scores (<cite>tuple(torch.FloatTensor)</cite>):</dt><dd><p>Transition scores for each vocabulary token at each generation step. Beam transition scores consisting
of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.
Tuple of <cite>torch.FloatTensor</cite> with up to <cite>max_new_tokens</cite> elements (one element for each generated token),
with each tensor of shape <cite>(batch_size*num_beams, config.vocab_size)</cite>.</p>
</dd>
<dt>beam_indices (<cite>torch.LongTensor</cite>, <em>optional</em>):</dt><dd><p>Beam indices of generated token id at each generation step. <cite>torch.LongTensor</cite> of shape
<cite>(batch_size*num_return_sequences, sequence_length)</cite>. Only required if a <cite>num_beams&gt;1</cite> at
generate-time.</p>
</dd>
<dt>normalize_logits (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether to normalize the logits (which, for legacy reasons, may be unnormalized).</p>
</dd>
</dl>
</dd>
<dt>Return:</dt><dd><dl class="simple">
<dt><cite>torch.Tensor</cite>: A <cite>torch.Tensor</cite> of shape <cite>(batch_size*num_return_sequences, sequence_length)</cite> containing</dt><dd><p>the transition scores (logits)</p>
</dd>
</dl>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>python
&gt;&gt;&gt; from transformers import GPT2Tokenizer, AutoModelForCausalLM
&gt;&gt;&gt; import numpy as np</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai-community/gpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="s2">&quot;Today is&quot;</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Print the scores for each token generated with Greedy Search</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_dict_in_generate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transition_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">compute_transition_scores</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">outputs</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span> <span class="n">normalize_logits</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># input_length is the length of the input prompt for decoder-only models, like the GPT family, and 1 for</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># encoder-decoder models, like BART or T5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_length</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_encoder_decoder</span> <span class="k">else</span> <span class="n">inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">sequences</span><span class="p">[:,</span> <span class="n">input_length</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">transition_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span class="gp">... </span>    <span class="c1"># | token | token string | log probability | probability</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;| </span><span class="si">{</span><span class="n">tok</span><span class="si">:</span><span class="s2">5d</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span><span class="si">:</span><span class="s2">8s</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">score</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">|   262 |  the     | -1.414 | 24.33%</span>
<span class="go">|  1110 |  day     | -2.609 | 7.36%</span>
<span class="go">|   618 |  when    | -2.010 | 13.40%</span>
<span class="go">|   356 |  we      | -1.859 | 15.58%</span>
<span class="go">|   460 |  can     | -2.508 | 8.14%</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: Reconstruct the sequence scores from Beam Search</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
<span class="gp">... </span>    <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_beams</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">return_dict_in_generate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transition_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">compute_transition_scores</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">outputs</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">beam_indices</span><span class="p">,</span> <span class="n">normalize_logits</span><span class="o">=</span><span class="kc">False</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If you sum the generated tokens&#39; scores and apply the length penalty, you&#39;ll get the sequence scores.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Tip 1: recomputing the scores is only guaranteed to match with `normalize_logits=False`. Depending on the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use case, you might want to recompute it with `normalize_logits=True`.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Tip 2: the output length does NOT include the input length</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_length</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">transition_scores</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">length_penalty</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">length_penalty</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reconstructed_scores</span> <span class="o">=</span> <span class="n">transition_scores</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">output_length</span><span class="o">**</span><span class="n">length_penalty</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">sequences_scores</span><span class="p">,</span> <span class="n">reconstructed_scores</span><span class="p">))</span>
<span class="go">True</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.config_class">
<span class="sig-name descname"><span class="pre">config_class</span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.config_class" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">ChartClassifierConfig</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.constrained_beam_search">
<span class="sig-name descname"><span class="pre">constrained_beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.constrained_beam_search" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.contrastive_search">
<span class="sig-name descname"><span class="pre">contrastive_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.contrastive_search" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.cpu" title="Permalink to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.create_extended_attention_mask_for_decoder">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_extended_attention_mask_for_decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.create_extended_attention_mask_for_decoder" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.cuda" title="Permalink to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (int, optional): if specified, all parameters will be</dt><dd><p>copied to that device</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.device" title="Permalink to this definition"></a></dt>
<dd><p><cite>torch.device</cite>: The device on which the module is (assuming that all the module parameters are on the same
device).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.disable_adapters">
<span class="sig-name descname"><span class="pre">disable_adapters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.disable_adapters" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Disable all adapters that are attached to the model. This leads to inferring with the base model only.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.disable_input_require_grads">
<span class="sig-name descname"><span class="pre">disable_input_require_grads</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.disable_input_require_grads" title="Permalink to this definition"></a></dt>
<dd><p>Removes the <cite>_require_grads_hook</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.double" title="Permalink to this definition"></a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.dtype" title="Permalink to this definition"></a></dt>
<dd><p><cite>torch.dtype</cite>: The dtype of the module (assuming that all the module parameters have the same dtype).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.dummy_inputs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dummy_inputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.dummy_inputs" title="Permalink to this definition"></a></dt>
<dd><p><cite>Dict[str, torch.Tensor]</cite>: Dummy inputs to do a forward pass in the network.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.dump_patches" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.enable_adapters">
<span class="sig-name descname"><span class="pre">enable_adapters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.enable_adapters" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Enable adapters that are attached to the model. The model will use <cite>self.active_adapter()</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.enable_input_require_grads">
<span class="sig-name descname"><span class="pre">enable_input_require_grads</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.enable_input_require_grads" title="Permalink to this definition"></a></dt>
<dd><p>Enables the gradients for the input embeddings. This is useful for fine-tuning adapter weights while keeping
the model weights fixed.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.estimate_tokens">
<span class="sig-name descname"><span class="pre">estimate_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.estimate_tokens" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to estimate the total number of tokens from the model inputs.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>inputs (<cite>dict</cite>): The model inputs.</p>
</dd>
<dt>Returns:</dt><dd><p><cite>int</cite>: The total number of tokens.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.eval" title="Permalink to this definition"></a></dt>
<dd><p>Set the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.extra_repr" title="Permalink to this definition"></a></dt>
<dd><p>Set the extra representation of the module.</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.float" title="Permalink to this definition"></a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.floating_point_ops">
<span class="sig-name descname"><span class="pre">floating_point_ops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.floating_point_ops" title="Permalink to this definition"></a></dt>
<dd><p>Get number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a
batch with this transformer model. Default approximation neglects the quadratic dependency on the number of
tokens (valid if <cite>12 * d_model &lt;&lt; sequence_length</cite>) as laid out in [this
paper](<a class="reference external" href="https://arxiv.org/pdf/2001.08361.pdf">https://arxiv.org/pdf/2001.08361.pdf</a>) section 2.1. Should be overridden for transformers with parameter
re-use e.g. Albert or Universal Transformers, or if doing long-range modeling with very high sequence lengths.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>batch_size (<cite>int</cite>):</dt><dd><p>The batch size for the forward pass.</p>
</dd>
<dt>sequence_length (<cite>int</cite>):</dt><dd><p>The number of tokens in each line of the batch.</p>
</dd>
<dt>exclude_embeddings (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether or not to count embedding and softmax operations.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p><cite>int</cite>: The number of floating-point operations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_type_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">position_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs_embeds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.BoolTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ChartClassifierOutput</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#BertForChartClassification.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.forward" title="Permalink to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.framework">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">framework</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.framework" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Str<span class="colon">:</span></dt>
<dd class="field-odd"><p>Identifies that this is a PyTorch model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PathLike</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">model_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PretrainedConfig</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PathLike</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PathLike</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_mismatched_sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_files_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">revision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'main'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_safetensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Instantiate a pretrained pytorch model from a pre-trained model configuration.</p>
<p>The model is set in evaluation mode by default using <cite>model.eval()</cite> (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with <cite>model.train()</cite>.</p>
<p>The warning <em>Weights from XXX not initialized from pretrained model</em> means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.</p>
<p>The warning <em>Weights from XXX not used in YYY</em> means that the layer XXX is not used by YYY, therefore those
weights are discarded.</p>
<dl>
<dt>Parameters:</dt><dd><dl>
<dt>pretrained_model_name_or_path (<cite>str</cite> or <cite>os.PathLike</cite>, <em>optional</em>):</dt><dd><p>Can be either:</p>
<blockquote>
<div><ul class="simple">
<li><p>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.</p></li>
<li><p>A path to a <em>directory</em> containing model weights saved using
[<cite>~PreTrainedModel.save_pretrained</cite>], e.g., <cite>./my_model_directory/</cite>.</p></li>
<li><p>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <cite>./tf_model/model.ckpt.index</cite>). In
this case, <cite>from_tf</cite> should be set to <cite>True</cite> and a configuration object should be provided as
<cite>config</cite> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</p></li>
<li><p>A path or url to a model folder containing a <em>flax checkpoint file</em> in <em>.msgpack</em> format (e.g,
<cite>./flax_model/</cite> containing <cite>flax_model.msgpack</cite>). In this case, <cite>from_flax</cite> should be set to
<cite>True</cite>.</p></li>
<li><p><cite>None</cite> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <cite>config</cite> and <cite>state_dict</cite>).</p></li>
</ul>
</div></blockquote>
</dd>
<dt>model_args (sequence of positional arguments, <em>optional</em>):</dt><dd><p>All remaining positional arguments will be passed to the underlying model’s <cite>__init__</cite> method.</p>
</dd>
<dt>config (<cite>Union[PretrainedConfig, str, os.PathLike]</cite>, <em>optional</em>):</dt><dd><p>Can be either:</p>
<blockquote>
<div><ul class="simple">
<li><p>an instance of a class derived from [<cite>PretrainedConfig</cite>],</p></li>
<li><p>a string or path valid as input to [<cite>~PretrainedConfig.from_pretrained</cite>].</p></li>
</ul>
</div></blockquote>
<p>Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<blockquote>
<div><ul class="simple">
<li><p>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</p></li>
<li><p>The model was saved using [<cite>~PreTrainedModel.save_pretrained</cite>] and is reloaded by supplying the
save directory.</p></li>
<li><p>The model is loaded by supplying a local directory as <cite>pretrained_model_name_or_path</cite> and a
configuration JSON file named <em>config.json</em> is found in the directory.</p></li>
</ul>
</div></blockquote>
</dd>
<dt>state_dict (<cite>Dict[str, torch.Tensor]</cite>, <em>optional</em>):</dt><dd><p>A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using [<cite>~PreTrainedModel.save_pretrained</cite>] and
[<cite>~PreTrainedModel.from_pretrained</cite>] is not a simpler option.</p>
</dd>
<dt>cache_dir (<cite>Union[str, os.PathLike]</cite>, <em>optional</em>):</dt><dd><p>Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.</p>
</dd>
<dt>from_tf (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Load the model weights from a TensorFlow checkpoint save file (see docstring of
<cite>pretrained_model_name_or_path</cite> argument).</p>
</dd>
<dt>from_flax (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Load the model weights from a Flax checkpoint save file (see docstring of
<cite>pretrained_model_name_or_path</cite> argument).</p>
</dd>
<dt>ignore_mismatched_sizes (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to raise an error if some of the weights from the checkpoint do not have the same size
as the weights of the model (if for instance, you are instantiating a model with 10 labels from a
checkpoint with 3 labels).</p>
</dd>
<dt>force_download (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.</p>
</dd>
<dt>resume_download (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.</p>
</dd>
<dt>proxies (<cite>Dict[str, str]</cite>, <em>optional</em>):</dt><dd><p>A dictionary of proxy servers to use by protocol or endpoint, e.g., <cite>{‘http’: ‘foo.bar:3128’,
‘http://hostname’: ‘foo.bar:4012’}</cite>. The proxies are used on each request.</p>
</dd>
<dt>output_loading_info(<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.</p>
</dd>
<dt>local_files_only(<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to only look at local files (i.e., do not try to download the model).</p>
</dd>
<dt>token (<cite>str</cite> or <cite>bool</cite>, <em>optional</em>):</dt><dd><p>The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, or not specified, will use
the token generated when running <cite>huggingface-cli login</cite> (stored in <cite>~/.huggingface</cite>).</p>
</dd>
<dt>revision (<cite>str</cite>, <em>optional</em>, defaults to <cite>“main”</cite>):</dt><dd><p>The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <cite>revision</cite> can be any
identifier allowed by git.</p>
<p>&lt;Tip&gt;</p>
<p>To test a pull request you made on the Hub, you can pass <a href="#id13"><span class="problematic" id="id14">`</span></a>revision=”refs/pr/&lt;pr_number&gt;”.</p>
<p>&lt;/Tip&gt;</p>
</dd>
<dt>mirror (<cite>str</cite>, <em>optional</em>):</dt><dd><p>Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information.</p>
</dd>
<dt>_fast_init(<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether or not to disable fast initialization.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>One should only disable <em>_fast_init</em> to ensure backwards compatibility with <cite>transformers.__version__ &lt;
4.6.0</cite> for seeded model initialization. This argument will be removed at the next major version. See
[pull request 11471](<a class="reference external" href="https://github.com/huggingface/transformers/pull/11471">https://github.com/huggingface/transformers/pull/11471</a>) for more information.</p>
<p>&lt;/Tip&gt;</p>
</dd>
<dt>attn_implementation (<cite>str</cite>, <em>optional</em>):</dt><dd><p>The attention implementation to use in the model (if relevant). Can be any of <cite>“eager”</cite> (manual implementation of the attention), <cite>“sdpa”</cite> (using [<cite>F.scaled_dot_product_attention</cite>](<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html">https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html</a>)), or <cite>“flash_attention_2”</cite> (using [Dao-AILab/flash-attention](<a class="reference external" href="https://github.com/Dao-AILab/flash-attention">https://github.com/Dao-AILab/flash-attention</a>)). By default, if available, SDPA will be used for torch&gt;=2.1.1. The default is otherwise the manual <cite>“eager”</cite> implementation.</p>
</dd>
</dl>
<p>&gt; Parameters for big model inference</p>
<dl>
<dt>low_cpu_mem_usage(<cite>bool</cite>, <em>optional</em>):</dt><dd><p>Tries to not use more than 1x model size in CPU memory (including peak memory) while loading the model.
This is an experimental feature and a subject to change at any moment.</p>
</dd>
<dt>torch_dtype (<cite>str</cite> or <cite>torch.dtype</cite>, <em>optional</em>):</dt><dd><p>Override the default <cite>torch.dtype</cite> and load the model under a specific <cite>dtype</cite>. The different options
are:</p>
<ol class="arabic simple">
<li><p><cite>torch.float16</cite> or <cite>torch.bfloat16</cite> or <cite>torch.float</cite>: load in a specified</p></li>
</ol>
<blockquote>
<div><p><cite>dtype</cite>, ignoring the model’s <cite>config.torch_dtype</cite> if one exists. If not specified
- the model will get loaded in <cite>torch.float</cite> (fp32).</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p><cite>“auto”</cite> - A <cite>torch_dtype</cite> entry in the <cite>config.json</cite> file of the model will be</p></li>
</ol>
<blockquote>
<div><p>attempted to be used. If this entry isn’t found then next check the <cite>dtype</cite> of the first weight in
the checkpoint that’s of a floating point type and use that as <cite>dtype</cite>. This will load the model
using the <cite>dtype</cite> it was saved in at the end of the training. It can’t be used as an indicator of how
the model was trained. Since it could be trained in one of half precision dtypes, but saved in fp32.</p>
</div></blockquote>
<p>&lt;Tip&gt;</p>
<p>For some models the <cite>dtype</cite> they were trained in is unknown - you may try to check the model’s paper or
reach out to the authors and ask them to add this information to the model’s card and to insert the
<cite>torch_dtype</cite> entry in <cite>config.json</cite> on the hub.</p>
<p>&lt;/Tip&gt;</p>
</dd>
<dt>device_map (<cite>str</cite> or <cite>Dict[str, Union[int, str, torch.device]]</cite> or <cite>int</cite> or <cite>torch.device</cite>, <em>optional</em>):</dt><dd><p>A map that specifies where each submodule should go. It doesn’t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device. If we only pass the device (<em>e.g.</em>, <cite>“cpu”</cite>, <cite>“cuda:1”</cite>, <cite>“mps”</cite>, or a GPU ordinal rank
like <cite>1</cite>) on which the model will be allocated, the device map will map the entire model to this
device. Passing <cite>device_map = 0</cite> means put the whole model on GPU 0.</p>
<p>To have Accelerate compute the most optimized <cite>device_map</cite> automatically, set <cite>device_map=”auto”</cite>. For
more information about each option see [designing a device
map](<a class="reference external" href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map">https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map</a>).</p>
</dd>
<dt>max_memory (<cite>Dict</cite>, <em>optional</em>):</dt><dd><p>A dictionary device identifier to maximum memory. Will default to the maximum memory available for each
GPU and the available CPU RAM if unset.</p>
</dd>
<dt>offload_folder (<cite>str</cite> or <cite>os.PathLike</cite>, <em>optional</em>):</dt><dd><p>If the <cite>device_map</cite> contains any value <cite>“disk”</cite>, the folder where we will offload weights.</p>
</dd>
<dt>offload_state_dict (<cite>bool</cite>, <em>optional</em>):</dt><dd><p>If <cite>True</cite>, will temporarily offload the CPU state dict to the hard drive to avoid getting out of CPU
RAM if the weight of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults to
<cite>True</cite> when there is some disk offload.</p>
</dd>
<dt>offload_buffers (<cite>bool</cite>, <em>optional</em>):</dt><dd><p>Whether or not to offload the buffers with the model parameters.</p>
</dd>
<dt>quantization_config (<cite>Union[QuantizationConfigMixin,Dict]</cite>, <em>optional</em>):</dt><dd><p>A dictionary of configuration parameters or a QuantizationConfigMixin object for quantization (e.g
bitsandbytes, gptq). There may be other quantization-related kwargs, including <cite>load_in_4bit</cite> and
<cite>load_in_8bit</cite>, which are parsed by QuantizationConfigParser. Supported only for bitsandbytes
quantizations and not preferred. consider inserting all such arguments into quantization_config
instead.</p>
</dd>
<dt>subfolder (<cite>str</cite>, <em>optional</em>, defaults to <cite>“”</cite>):</dt><dd><p>In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can
specify the folder name here.</p>
</dd>
<dt>variant (<cite>str</cite>, <em>optional</em>):</dt><dd><p>If specified load weights from <cite>variant</cite> filename, <em>e.g.</em> pytorch_model.&lt;variant&gt;.bin. <cite>variant</cite> is
ignored when using <cite>from_tf</cite> or <cite>from_flax</cite>.</p>
</dd>
<dt>use_safetensors (<cite>bool</cite>, <em>optional</em>, defaults to <cite>None</cite>):</dt><dd><p>Whether or not to use <cite>safetensors</cite> checkpoints. Defaults to <cite>None</cite>. If not specified and <cite>safetensors</cite>
is not installed, it will be set to <cite>False</cite>.</p>
</dd>
<dt>kwargs (remaining dictionary of keyword arguments, <em>optional</em>):</dt><dd><p>Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<cite>output_attentions=True</cite>). Behaves differently depending on whether a <cite>config</cite> is provided or
automatically loaded:</p>
<blockquote>
<div><ul class="simple">
<li><p>If a configuration is provided with <cite>config</cite>, <cite>**kwargs</cite> will be directly passed to the
underlying model’s <cite>__init__</cite> method (we assume all relevant updates to the configuration have
already been done)</p></li>
<li><p>If a configuration is not provided, <cite>kwargs</cite> will be first passed to the configuration class
initialization function ([<cite>~PretrainedConfig.from_pretrained</cite>]). Each key of <cite>kwargs</cite> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <cite>kwargs</cite> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model’s <cite>__init__</cite> function.</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p>&lt;Tip&gt;</p>
<p>Activate the special [“offline-mode”](<a class="reference external" href="https://huggingface.co/transformers/installation.html#offline-mode">https://huggingface.co/transformers/installation.html#offline-mode</a>) to
use this method in a firewalled environment.</p>
<p>&lt;/Tip&gt;</p>
<p>Examples:</p>
<p><a href="#id15"><span class="problematic" id="id16">``</span></a><a href="#id17"><span class="problematic" id="id18">`</span></a>python
&gt;&gt;&gt; from transformers import BertConfig, BertModel</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Download model and configuration from huggingface.co and cache.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Model was saved using *save_pretrained(&#39;./test/saved_model/&#39;)* (for example purposes, not runnable).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./test/saved_model/&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Update configuration during loading.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span> <span class="o">==</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading from a TF checkpoint file instead of a PyTorch model (slower, for example purposes, not runnable).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span><span class="s2">&quot;./tf_model/my_tf_model_config.json&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./tf_model/my_tf_checkpoint.ckpt.index&quot;</span><span class="p">,</span> <span class="n">from_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading from a Flax checkpoint file instead of a PyTorch model (slower)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">from_flax</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">```</span>
</pre></div>
</div>
<ul class="simple">
<li><p><cite>low_cpu_mem_usage</cite> algorithm:</p></li>
</ul>
<p>This is an experimental function that loads the model using ~1x model size CPU memory</p>
<p>Here is how it works:</p>
<ol class="arabic simple">
<li><p>save which state_dict keys we have</p></li>
<li><p>drop state_dict before the model is created, since the latter takes 1x model size CPU memory</p></li>
</ol>
<p>3. after the model has been instantiated switch to the meta device all params/buffers that
are going to be replaced from the loaded state_dict
4. load state_dict 2nd time
5. replace the params/buffers from the state_dict</p>
<p>Currently, it can’t handle deepspeed ZeRO stage 3 and ignores loading errors</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">GenerationConfig</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LogitsProcessorList</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">StoppingCriteriaList</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_allowed_tokens_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assistant_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streamer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaseStreamer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_prompt_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_prompt_attention_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">GenerateDecoderOnlyOutput</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">GenerateEncoderDecoderOutput</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">GenerateBeamDecoderOnlyOutput</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">GenerateBeamEncoderDecoderOutput</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">LongTensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.generate" title="Permalink to this definition"></a></dt>
<dd><p>Generates sequences of token ids for models with a language modeling head.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>Most generation-controlling parameters are set in <cite>generation_config</cite> which, if not passed, will be set to the
model’s default generation configuration. You can override any <cite>generation_config</cite> by passing the corresponding
parameters to generate(), e.g. <cite>.generate(inputs, num_beams=4, do_sample=True)</cite>.</p>
<p>For an overview of generation strategies and code examples, check out the [following
guide](../generation_strategies).</p>
<p>&lt;/Tip&gt;</p>
<dl>
<dt>Parameters:</dt><dd><dl class="simple">
<dt>inputs (<cite>torch.Tensor</cite> of varying shape depending on the modality, <em>optional</em>):</dt><dd><p>The sequence used as a prompt for the generation or as model inputs to the encoder. If <cite>None</cite> the
method initializes it with <cite>bos_token_id</cite> and a batch size of 1. For decoder-only models <cite>inputs</cite>
should be in the format of <cite>input_ids</cite>. For encoder-decoder models <em>inputs</em> can represent any of
<cite>input_ids</cite>, <cite>input_values</cite>, <cite>input_features</cite>, or <cite>pixel_values</cite>.</p>
</dd>
<dt>generation_config (<cite>~generation.GenerationConfig</cite>, <em>optional</em>):</dt><dd><p>The generation configuration to be used as base parametrization for the generation call. <cite>**kwargs</cite>
passed to generate matching the attributes of <cite>generation_config</cite> will override them. If
<cite>generation_config</cite> is not provided, the default will be used, which has the following loading
priority: 1) from the <cite>generation_config.json</cite> model file, if it exists; 2) from the model
configuration. Please note that unspecified parameters will inherit [<cite>~generation.GenerationConfig</cite>]’s
default values, whose documentation should be checked to parameterize generation.</p>
</dd>
<dt>logits_processor (<cite>LogitsProcessorList</cite>, <em>optional</em>):</dt><dd><p>Custom logits processors that complement the default logits processors built from arguments and
generation config. If a logit processor is passed that is already created with the arguments or a
generation config an error is thrown. This feature is intended for advanced users.</p>
</dd>
<dt>stopping_criteria (<cite>StoppingCriteriaList</cite>, <em>optional</em>):</dt><dd><p>Custom stopping criteria that complements the default stopping criteria built from arguments and a
generation config. If a stopping criteria is passed that is already created with the arguments or a
generation config an error is thrown. If your stopping criteria depends on the <cite>scores</cite> input, make
sure you pass <cite>return_dict_in_generate=True, output_scores=True</cite> to <cite>generate</cite>. This feature is
intended for advanced users.</p>
</dd>
<dt>prefix_allowed_tokens_fn (<cite>Callable[[int, torch.Tensor], List[int]]</cite>, <em>optional</em>):</dt><dd><p>If provided, this function constraints the beam search to allowed tokens only at each step. If not
provided no constraint is applied. This function takes 2 arguments: the batch ID <cite>batch_id</cite> and
<cite>input_ids</cite>. It has to return a list with the allowed tokens for the next generation step conditioned
on the batch ID <cite>batch_id</cite> and the previously generated tokens <cite>inputs_ids</cite>. This argument is useful
for constrained generation conditioned on the prefix, as described in [Autoregressive Entity
Retrieval](<a class="reference external" href="https://arxiv.org/abs/2010.00904">https://arxiv.org/abs/2010.00904</a>).</p>
</dd>
<dt>synced_gpus (<cite>bool</cite>, <em>optional</em>):</dt><dd><p>Whether to continue running the while loop until max_length. Unless overridden this flag will be set to
<cite>True</cite> under DeepSpeed ZeRO Stage 3 multiple GPUs environment to avoid hanging if one GPU finished
generating before other GPUs. Otherwise it’ll be set to <cite>False</cite>.</p>
</dd>
<dt>assistant_model (<cite>PreTrainedModel</cite>, <em>optional</em>):</dt><dd><p>An assistant model that can be used to accelerate generation. The assistant model must have the exact
same tokenizer. The acceleration is achieved when forecasting candidate tokens with the assistent model
is much faster than running generation with the model you’re calling generate from. As such, the
assistant model should be much smaller.</p>
</dd>
<dt>streamer (<cite>BaseStreamer</cite>, <em>optional</em>):</dt><dd><p>Streamer object that will be used to stream the generated sequences. Generated tokens are passed
through <cite>streamer.put(token_ids)</cite> and the streamer is responsible for any further processing.</p>
</dd>
<dt>negative_prompt_ids (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>, <em>optional</em>):</dt><dd><p>The negative prompt needed for some processors such as CFG. The batch size must match the input batch
size. This is an experimental feature, subject to breaking API changes in future versions.</p>
</dd>
<dt>negative_prompt_attention_mask (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>, <em>optional</em>):</dt><dd><p>Attention_mask for <cite>negative_prompt_ids</cite>.</p>
</dd>
<dt>kwargs (<cite>Dict[str, Any]</cite>, <em>optional</em>):</dt><dd><p>Ad hoc parametrization of <cite>generation_config</cite> and/or additional model-specific kwargs that will be
forwarded to the <cite>forward</cite> function of the model. If the model is an encoder-decoder model, encoder
specific kwargs should not be prefixed and decoder specific kwargs should be prefixed with <em>decoder_</em>.</p>
</dd>
</dl>
</dd>
<dt>Return:</dt><dd><p>[<cite>~utils.ModelOutput</cite>] or <cite>torch.LongTensor</cite>: A [<cite>~utils.ModelOutput</cite>] (if <cite>return_dict_in_generate=True</cite>
or when <cite>config.return_dict_in_generate=True</cite>) or a <cite>torch.FloatTensor</cite>.</p>
<blockquote>
<div><p>If the model is <em>not</em> an encoder-decoder model (<cite>model.config.is_encoder_decoder=False</cite>), the possible
[<cite>~utils.ModelOutput</cite>] types are:</p>
<blockquote>
<div><ul class="simple">
<li><p>[<cite>~generation.GenerateDecoderOnlyOutput</cite>],</p></li>
<li><p>[<cite>~generation.GenerateBeamDecoderOnlyOutput</cite>]</p></li>
</ul>
</div></blockquote>
<p>If the model is an encoder-decoder model (<cite>model.config.is_encoder_decoder=True</cite>), the possible
[<cite>~utils.ModelOutput</cite>] types are:</p>
<blockquote>
<div><ul class="simple">
<li><p>[<cite>~generation.GenerateEncoderDecoderOutput</cite>],</p></li>
<li><p>[<cite>~generation.GenerateBeamEncoderDecoderOutput</cite>]</p></li>
</ul>
</div></blockquote>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_adapter_state_dict">
<span class="sig-name descname"><span class="pre">get_adapter_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adapter_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_adapter_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Gets the adapter state dict that should only contain the weights tensors of the specified adapter_name adapter.
If no adapter_name is passed, the active adapter is used.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>adapter_name (<cite>str</cite>, <em>optional</em>):</dt><dd><p>The name of the adapter to get the state dict from. If no name is passed, the active adapter is used.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Return the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>target: The fully-qualified string name of the buffer</dt><dd><p>to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt>Raises:</dt><dd><dl class="simple">
<dt>AttributeError: If the target string references an invalid</dt><dd><p>path or resolves to something that is not a
buffer</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_extended_attention_mask">
<span class="sig-name descname"><span class="pre">get_extended_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.float32</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_extended_attention_mask" title="Permalink to this definition"></a></dt>
<dd><p>Makes broadcastable attention and causal masks so that future and masked tokens are ignored.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>attention_mask (<cite>torch.Tensor</cite>):</dt><dd><p>Mask with ones indicating tokens to attend to, zeros for tokens to ignore.</p>
</dd>
<dt>input_shape (<cite>Tuple[int]</cite>):</dt><dd><p>The shape of the input to the model.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p><cite>torch.Tensor</cite> The extended attention mask, with a the same dtype as <cite>attention_mask.dtype</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_extra_state" title="Permalink to this definition"></a></dt>
<dd><p>Return any extra state to include in the module’s state_dict.</p>
<p>Implement this and a corresponding <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.set_extra_state" title="lambeq.bobcat.BertForChartClassification.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <cite>state_dict()</cite>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>object: Any extra state to store in the module’s state_dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_head_mask">
<span class="sig-name descname"><span class="pre">get_head_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_attention_chunked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_head_mask" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the head mask if needed.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>head_mask (<cite>torch.Tensor</cite> with shape <cite>[num_heads]</cite> or <cite>[num_hidden_layers x num_heads]</cite>, <em>optional</em>):</dt><dd><p>The mask indicating if we should keep the heads or not (1.0 for keep, 0.0 for discard).</p>
</dd>
<dt>num_hidden_layers (<cite>int</cite>):</dt><dd><p>The number of hidden layers in the model.</p>
</dd>
<dt>is_attention_chunked (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not the attentions scores are computed by chunks or not.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p><cite>torch.Tensor</cite> with shape <cite>[num_hidden_layers x batch x num_heads x seq_length x seq_length]</cite> or list with
<cite>[None]</cite> for each layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_input_embeddings">
<span class="sig-name descname"><span class="pre">get_input_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_input_embeddings" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model’s input embeddings.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p><cite>nn.Module</cite>: A torch module mapping vocabulary to hidden states.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_memory_footprint">
<span class="sig-name descname"><span class="pre">get_memory_footprint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">return_buffers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_memory_footprint" title="Permalink to this definition"></a></dt>
<dd><p>Get the memory footprint of a model. This will return the memory footprint of the current model in bytes.
Useful to benchmark the memory footprint of the current model and design some tests. Solution inspired from the
PyTorch discussions: <a class="reference external" href="https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2">https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822/2</a></p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>return_buffers (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether to return the size of the buffer tensors in the computation of the memory footprint. Buffers
are tensors that do not require gradients and not registered as parameters. E.g. mean and std in batch
norm layers. Please see: <a class="reference external" href="https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2">https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266/2</a></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_output_embeddings">
<span class="sig-name descname"><span class="pre">get_output_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_output_embeddings" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model’s output embeddings.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p><cite>nn.Module</cite>: A torch module mapping hidden states to vocabulary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Parameter</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_parameter" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>target: The fully-qualified string name of the Parameter</dt><dd><p>to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>torch.nn.Parameter: The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt>Raises:</dt><dd><dl class="simple">
<dt>AttributeError: If the target string references an invalid</dt><dd><p>path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_position_embeddings">
<span class="sig-name descname"><span class="pre">get_position_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Embedding</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Embedding</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_position_embeddings" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.get_submodule" title="Permalink to this definition"></a></dt>
<dd><p>Return the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>target: The fully-qualified string name of the submodule</dt><dd><p>to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>torch.nn.Module: The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt>Raises:</dt><dd><dl class="simple">
<dt>AttributeError: If the target string references an invalid</dt><dd><p>path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.gradient_checkpointing_disable">
<span class="sig-name descname"><span class="pre">gradient_checkpointing_disable</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.gradient_checkpointing_disable" title="Permalink to this definition"></a></dt>
<dd><p>Deactivates gradient checkpointing for the current model.</p>
<p>Note that in other frameworks this feature can be referred to as “activation checkpointing” or “checkpoint
activations”.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.gradient_checkpointing_enable">
<span class="sig-name descname"><span class="pre">gradient_checkpointing_enable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_checkpointing_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.gradient_checkpointing_enable" title="Permalink to this definition"></a></dt>
<dd><p>Activates gradient checkpointing for the current model.</p>
<p>Note that in other frameworks this feature can be referred to as “activation checkpointing” or “checkpoint
activations”.</p>
<p>We pass the <cite>__call__</cite> method of the modules instead of <cite>forward</cite> because <cite>__call__</cite> attaches all the hooks of
the module. <a class="reference external" href="https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2">https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690/2</a></p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>gradient_checkpointing_kwargs (dict, <em>optional</em>):</dt><dd><p>Additional keyword arguments passed along to the <cite>torch.utils.checkpoint.checkpoint</cite> function.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.greedy_search">
<span class="sig-name descname"><span class="pre">greedy_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.greedy_search" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.group_beam_search">
<span class="sig-name descname"><span class="pre">group_beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.group_beam_search" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.half" title="Permalink to this definition"></a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.init_weights" title="Permalink to this definition"></a></dt>
<dd><p>If needed prunes and maybe initializes weights. If using a custom <cite>PreTrainedModel</cite>, you need to implement any
initialization logic in <cite>_init_weights</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.invert_attention_mask">
<span class="sig-name descname"><span class="pre">invert_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_attention_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.invert_attention_mask" title="Permalink to this definition"></a></dt>
<dd><p>Invert an attention mask (e.g., switches 0. and 1.).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>encoder_attention_mask (<cite>torch.Tensor</cite>): An attention mask.</p>
</dd>
<dt>Returns:</dt><dd><p><cite>torch.Tensor</cite>: The inverted attention mask.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.ipu" title="Permalink to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>device (int, optional): if specified, all parameters will be</dt><dd><p>copied to that device</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.is_gradient_checkpointing">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_gradient_checkpointing</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.is_gradient_checkpointing" title="Permalink to this definition"></a></dt>
<dd><p>Whether gradient checkpointing is activated for this model or not.</p>
<p>Note that in other frameworks this feature can be referred to as “activation checkpointing” or “checkpoint
activations”.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.is_parallelizable">
<span class="sig-name descname"><span class="pre">is_parallelizable</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.is_parallelizable" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.load_adapter">
<span class="sig-name descname"><span class="pre">load_adapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">peft_model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">revision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_memory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload_folder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peft_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.load_adapter" title="Permalink to this definition"></a></dt>
<dd><p>Load adapter weights from file or remote Hub folder. If you are not familiar with adapters and PEFT methods, we
invite you to read more about them on PEFT official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Requires peft as a backend to load the adapter weights.</p>
<dl>
<dt>Args:</dt><dd><dl>
<dt>peft_model_id (<cite>str</cite>, <em>optional</em>):</dt><dd><p>The identifier of the model to look for on the Hub, or a local path to the saved adapter config file
and adapter weights.</p>
</dd>
<dt>adapter_name (<cite>str</cite>, <em>optional</em>):</dt><dd><p>The adapter name to use. If not set, will use the default adapter.</p>
</dd>
<dt>revision (<cite>str</cite>, <em>optional</em>, defaults to <cite>“main”</cite>):</dt><dd><p>The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <cite>revision</cite> can be any
identifier allowed by git.</p>
<p>&lt;Tip&gt;</p>
<p>To test a pull request you made on the Hub, you can pass <a href="#id19"><span class="problematic" id="id20">`</span></a>revision=”refs/pr/&lt;pr_number&gt;”.</p>
<p>&lt;/Tip&gt;</p>
</dd>
<dt>token (<cite>str</cite>, <cite>optional</cite>):</dt><dd><p>Whether to use authentication token to load the remote folder. Userful to load private repositories
that are on HuggingFace Hub. You might need to call <cite>huggingface-cli login</cite> and paste your tokens to
cache it.</p>
</dd>
<dt>device_map (<cite>str</cite> or <cite>Dict[str, Union[int, str, torch.device]]</cite> or <cite>int</cite> or <cite>torch.device</cite>, <em>optional</em>):</dt><dd><p>A map that specifies where each submodule should go. It doesn’t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device. If we only pass the device (<em>e.g.</em>, <cite>“cpu”</cite>, <cite>“cuda:1”</cite>, <cite>“mps”</cite>, or a GPU ordinal rank
like <cite>1</cite>) on which the model will be allocated, the device map will map the entire model to this
device. Passing <cite>device_map = 0</cite> means put the whole model on GPU 0.</p>
<p>To have Accelerate compute the most optimized <cite>device_map</cite> automatically, set <cite>device_map=”auto”</cite>. For
more information about each option see [designing a device
map](<a class="reference external" href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map">https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map</a>).</p>
</dd>
<dt>max_memory (<cite>Dict</cite>, <em>optional</em>):</dt><dd><p>A dictionary device identifier to maximum memory. Will default to the maximum memory available for each
GPU and the available CPU RAM if unset.</p>
</dd>
<dt>offload_folder (<cite>str</cite> or <cite>os.PathLike</cite>, <cite>optional</cite>):</dt><dd><p>If the <cite>device_map</cite> contains any value <cite>“disk”</cite>, the folder where we will offload weights.</p>
</dd>
<dt>offload_index (<cite>int</cite>, <cite>optional</cite>):</dt><dd><p><cite>offload_index</cite> argument to be passed to <cite>accelerate.dispatch_model</cite> method.</p>
</dd>
<dt>peft_config (<cite>Dict[str, Any]</cite>, <em>optional</em>):</dt><dd><p>The configuration of the adapter to add, supported adapters are non-prefix tuning and adaption prompts
methods. This argument is used in case users directly pass PEFT state dicts</p>
</dd>
<dt>adapter_state_dict (<cite>Dict[str, torch.Tensor]</cite>, <em>optional</em>):</dt><dd><p>The state dict of the adapter to load. This argument is used in case users directly pass PEFT state
dicts</p>
</dd>
<dt>adapter_kwargs (<cite>Dict[str, Any]</cite>, <em>optional</em>):</dt><dd><p>Additional keyword arguments passed along to the <cite>from_pretrained</cite> method of the adapter config and
<cite>find_adapter_config_file</cite> method.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>Copy parameters and buffers from <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.load_state_dict" title="lambeq.bobcat.BertForChartClassification.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a>.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>state_dict (dict): a dict containing parameters and</dt><dd><p>persistent buffers.</p>
</dd>
<dt>strict (bool, optional): whether to strictly enforce that the keys</dt><dd><p>in <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
</dd>
<dt>assign (bool, optional): whether to assign items in the state</dt><dd><p>dictionary to their corresponding keys in the module instead
of copying them inplace into the module’s current parameters and buffers.
When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors in the current
module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the properties of the
Tensors in the state dict are preserved.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields:</dt><dd><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>Note:</dt><dd><p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.load_state_dict" title="lambeq.bobcat.BertForChartClassification.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.load_tf_weights">
<span class="sig-name descname"><span class="pre">load_tf_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tf_checkpoint_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.load_tf_weights" title="Permalink to this definition"></a></dt>
<dd><p>Load tf checkpoints in a pytorch model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.main_input_name">
<span class="sig-name descname"><span class="pre">main_input_name</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'input_ids'</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.main_input_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.model_tags">
<span class="sig-name descname"><span class="pre">model_tags</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.model_tags" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.modules" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over all modules in the network.</p>
<dl class="simple">
<dt>Yields:</dt><dd><p>Module: a module in the network</p>
</dd>
<dt>Note:</dt><dd><p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.named_buffers" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p>
<dl>
<dt>Args:</dt><dd><p>prefix (str): prefix to prepend to all buffer names.
recurse (bool, optional): if True, then yields buffers of this module</p>
<blockquote>
<div><p>and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p>
</div></blockquote>
<p>remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.</p>
</dd>
<dt>Yields:</dt><dd><p>(str, torch.Tensor): Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.named_children" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p>
<dl class="simple">
<dt>Yields:</dt><dd><p>(str, Module): Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.named_modules" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p>
<dl>
<dt>Args:</dt><dd><p>memo: a memo to store the set of modules already added to the result
prefix: a prefix that will be added to the name of the module
remove_duplicate: whether to remove the duplicated module instances in the result</p>
<blockquote>
<div><p>or not</p>
</div></blockquote>
</dd>
<dt>Yields:</dt><dd><p>(str, Module): Tuple of name and module</p>
</dd>
<dt>Note:</dt><dd><p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Parameter</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.named_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p>
<dl>
<dt>Args:</dt><dd><p>prefix (str): prefix to prepend to all parameter names.
recurse (bool): if True, then yields parameters of this module</p>
<blockquote>
<div><p>and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</div></blockquote>
<dl class="simple">
<dt>remove_duplicate (bool, optional): whether to remove the duplicated</dt><dd><p>parameters in the result. Defaults to True.</p>
</dd>
</dl>
</dd>
<dt>Yields:</dt><dd><p>(str, Parameter): Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.num_parameters">
<span class="sig-name descname"><span class="pre">num_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">only_trainable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.num_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Get number of (optionally, trainable or non-embeddings) parameters in the module.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>only_trainable (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to return only the number of trainable parameters</p>
</dd>
<dt>exclude_embeddings (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to return only the number of non-embeddings parameters</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p><cite>int</cite>: The number of parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Parameter</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>recurse (bool): if True, then yields parameters of this module</dt><dd><p>and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
</dl>
</dd>
<dt>Yields:</dt><dd><p>Parameter: module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.post_init">
<span class="sig-name descname"><span class="pre">post_init</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.post_init" title="Permalink to this definition"></a></dt>
<dd><p>A method executed at the end of each Transformer model initialization, to execute code that needs the model’s
modules properly initialized (such as weight initialization).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.prepare_inputs_for_generation">
<span class="sig-name descname"><span class="pre">prepare_inputs_for_generation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.prepare_inputs_for_generation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.prune_heads">
<span class="sig-name descname"><span class="pre">prune_heads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heads_to_prune</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.prune_heads" title="Permalink to this definition"></a></dt>
<dd><p>Prunes heads of the base model.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>heads_to_prune (<cite>Dict[int, List[int]]</cite>):</dt><dd><p>Dictionary with keys being selected layer indices (<cite>int</cite>) and associated values being the list of heads
to prune in said layer (list of <cite>int</cite>). For instance {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on
layer 1 and heads 2 and 3 on layer 2.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.push_to_hub">
<span class="sig-name descname"><span class="pre">push_to_hub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repo_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_temp_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">commit_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">private</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shard_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'5GB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_pr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">safe_serialization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">revision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">commit_description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">deprecated_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.push_to_hub" title="Permalink to this definition"></a></dt>
<dd><p>Upload the model file to the 🤗 Model Hub.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><dl class="simple">
<dt>repo_id (<cite>str</cite>):</dt><dd><p>The name of the repository you want to push your model to. It should contain your organization name
when pushing to a given organization.</p>
</dd>
<dt>use_temp_dir (<cite>bool</cite>, <em>optional</em>):</dt><dd><p>Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.
Will default to <cite>True</cite> if there is no directory named like <cite>repo_id</cite>, <cite>False</cite> otherwise.</p>
</dd>
<dt>commit_message (<cite>str</cite>, <em>optional</em>):</dt><dd><p>Message to commit while pushing. Will default to <cite>“Upload model”</cite>.</p>
</dd>
<dt>private (<cite>bool</cite>, <em>optional</em>):</dt><dd><p>Whether or not the repository created should be private.</p>
</dd>
<dt>token (<cite>bool</cite> or <cite>str</cite>, <em>optional</em>):</dt><dd><p>The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, will use the token generated
when running <cite>huggingface-cli login</cite> (stored in <cite>~/.huggingface</cite>). Will default to <cite>True</cite> if <cite>repo_url</cite>
is not specified.</p>
</dd>
<dt>max_shard_size (<cite>int</cite> or <cite>str</cite>, <em>optional</em>, defaults to <cite>“5GB”</cite>):</dt><dd><p>Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard
will then be each of size lower than this size. If expressed as a string, needs to be digits followed
by a unit (like <cite>“5MB”</cite>). We default it to <cite>“5GB”</cite> so that users can easily load models on free-tier
Google Colab instances without any CPU OOM issues.</p>
</dd>
<dt>create_pr (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to create a PR with the uploaded files or directly commit.</p>
</dd>
<dt>safe_serialization (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether or not to convert the model weights in safetensors format for safer serialization.</p>
</dd>
<dt>revision (<cite>str</cite>, <em>optional</em>):</dt><dd><p>Branch to push the uploaded files to.</p>
</dd>
<dt>commit_description (<cite>str</cite>, <em>optional</em>):</dt><dd><p>The description of the commit that will be created</p>
</dd>
<dt>tags (<cite>List[str]</cite>, <em>optional</em>):</dt><dd><p>List of tags to push on the Hub.</p>
</dd>
</dl>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a>python
from transformers import AutoModel</p>
<p>model = AutoModel.from_pretrained(“google-bert/bert-base-cased”)</p>
<p># Push the model to your namespace with the name “my-finetuned-bert”.
model.push_to_hub(“my-finetuned-bert”)</p>
<p># Push the model to an organization with the name “my-finetuned-bert”.
model.push_to_hub(“huggingface/my-finetuned-bert”)
<a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RemovableHandle</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_backward_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Add a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>name (str): name of the buffer. The buffer can be accessed</dt><dd><p>from this module using the given name</p>
</dd>
<dt>tensor (Tensor or None): buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations</dt><dd><p>that run on buffers, such as <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.cuda" title="lambeq.bobcat.BertForChartClassification.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
</dd>
<dt>persistent (bool): whether the buffer is part of this module’s</dt><dd><p><a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_for_auto_class">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">register_for_auto_class</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">auto_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AutoModel'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_for_auto_class" title="Permalink to this definition"></a></dt>
<dd><p>Register this class with a given auto class. This should only be used for custom models as the ones in the
library are already mapped with an auto class.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>This API is experimental and may have some slight breaking changes in the next releases.</p>
<p>&lt;/Tip&gt;</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>auto_class (<cite>str</cite> or <cite>type</cite>, <em>optional</em>, defaults to <cite>“AutoModel”</cite>):</dt><dd><p>The auto class to register this new model with.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RemovableHandle</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_forward_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.forward" title="lambeq.bobcat.BertForChartClassification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.forward" title="lambeq.bobcat.BertForChartClassification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl>
<dt>Args:</dt><dd><p>hook (Callable): The user defined hook to be registered.
prepend (bool): If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired</p>
<blockquote>
<div><p>before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</div></blockquote>
<dl class="simple">
<dt>with_kwargs (bool): If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the</dt><dd><p>kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
<dt>always_call (bool): If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of</dt><dd><p>whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RemovableHandle</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_forward_pre_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.forward" title="lambeq.bobcat.BertForChartClassification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl>
<dt>Args:</dt><dd><p>hook (Callable): The user defined hook to be registered.
prepend (bool): If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before</p>
<blockquote>
<div><p>all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</div></blockquote>
<dl class="simple">
<dt>with_kwargs (bool): If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs</dt><dd><p>given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RemovableHandle</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_full_backward_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl>
<dt>Args:</dt><dd><p>hook (Callable): The user-defined hook to be registered.
prepend (bool): If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before</p>
<blockquote>
<div><p>all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RemovableHandle</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_full_backward_pre_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl>
<dt>Args:</dt><dd><p>hook (Callable): The user-defined hook to be registered.
prepend (bool): If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before</p>
<blockquote>
<div><p>all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_load_state_dict_post_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a post hook to be run after module’s <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.load_state_dict" title="lambeq.bobcat.BertForChartClassification.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code>:</dt><dd><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_module" title="Permalink to this definition"></a></dt>
<dd><p>Alias for <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.add_module" title="lambeq.bobcat.BertForChartClassification.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Parameter</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_parameter" title="Permalink to this definition"></a></dt>
<dd><p>Add a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>name (str): name of the parameter. The parameter can be accessed</dt><dd><p>from this module using the given name</p>
</dd>
<dt>param (Parameter or None): parameter to be added to the module. If</dt><dd><p><code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.cuda" title="lambeq.bobcat.BertForChartClassification.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="lambeq.bobcat.BertForChartClassification.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.register_state_dict_pre_hook" title="Permalink to this definition"></a></dt>
<dd><p>Register a pre-hook for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> method.</p>
<p>These hooks will be called with arguments: <code class="docutils literal notranslate"><span class="pre">self</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code>,
and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> before calling <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> on <code class="docutils literal notranslate"><span class="pre">self</span></code>. The registered
hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.requires_grad_" title="Permalink to this definition"></a></dt>
<dd><p>Change if autograd should record operations on parameters in this module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>requires_grad (bool): whether autograd should record operations on</dt><dd><p>parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.reset_memory_hooks_state">
<span class="sig-name descname"><span class="pre">reset_memory_hooks_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.reset_memory_hooks_state" title="Permalink to this definition"></a></dt>
<dd><p>Reset the <cite>mem_rss_diff</cite> attribute of each module (see [<cite>~modeling_utils.ModuleUtilsMixin.add_memory_hooks</cite>]).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.resize_position_embeddings">
<span class="sig-name descname"><span class="pre">resize_position_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_num_position_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.resize_position_embeddings" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.resize_token_embeddings">
<span class="sig-name descname"><span class="pre">resize_token_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_num_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_to_multiple_of</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Embedding</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.resize_token_embeddings" title="Permalink to this definition"></a></dt>
<dd><p>Resizes input token embeddings matrix of the model if <cite>new_num_tokens != config.vocab_size</cite>.</p>
<p>Takes care of tying weights embeddings afterwards if the model class has a <cite>tie_weights()</cite> method.</p>
<dl>
<dt>Arguments:</dt><dd><dl>
<dt>new_num_tokens (<cite>int</cite>, <em>optional</em>):</dt><dd><p>The new number of tokens in the embedding matrix. Increasing the size will add newly initialized
vectors at the end. Reducing the size will remove vectors from the end. If not provided or <cite>None</cite>, just
returns a pointer to the input tokens <cite>torch.nn.Embedding</cite> module of the model without doing anything.</p>
</dd>
<dt>pad_to_multiple_of (<cite>int</cite>, <em>optional</em>):</dt><dd><p>If set will pad the embedding matrix to a multiple of the provided value.If <cite>new_num_tokens</cite> is set to
<cite>None</cite> will just pad the embedding to a multiple of <cite>pad_to_multiple_of</cite>.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability
<cite>&gt;= 7.5</cite> (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128. For more
details about this, or help on choosing the correct value for resizing, refer to this guide:
<a class="reference external" href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc">https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc</a></p>
</dd>
</dl>
</dd>
<dt>Return:</dt><dd><p><cite>torch.nn.Embedding</cite>: Pointer to the input tokens Embeddings Module of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.retrieve_modules_from_names">
<span class="sig-name descname"><span class="pre">retrieve_modules_from_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.retrieve_modules_from_names" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.reverse_bettertransformer">
<span class="sig-name descname"><span class="pre">reverse_bettertransformer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.reverse_bettertransformer" title="Permalink to this definition"></a></dt>
<dd><p>Reverts the transformation from [<cite>~PreTrainedModel.to_bettertransformer</cite>] so that the original modeling is
used, for example in order to save the model.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>[<cite>PreTrainedModel</cite>]: The model converted back to the original modeling.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.save_pretrained">
<span class="sig-name descname"><span class="pre">save_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_directory:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">~os.PathLike</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_main_process:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dict:</span> <span class="pre">dict</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">save&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shard_size:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'5GB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">safe_serialization:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variant:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token:</span> <span class="pre">bool</span> <span class="pre">|</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_peft_format:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.save_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Save a model and its configuration file to a directory, so that it can be re-loaded using the
[<cite>~PreTrainedModel.from_pretrained</cite>] class method.</p>
<dl>
<dt>Arguments:</dt><dd><dl>
<dt>save_directory (<cite>str</cite> or <cite>os.PathLike</cite>):</dt><dd><p>Directory to which to save. Will be created if it doesn’t exist.</p>
</dd>
<dt>is_main_process (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <cite>is_main_process=True</cite> only on
the main process to avoid race conditions.</p>
</dd>
<dt>state_dict (nested dictionary of <cite>torch.Tensor</cite>):</dt><dd><p>The state dictionary of the model to save. Will default to <cite>self.state_dict()</cite>, but can be used to only
save parts of the model or if special precautions need to be taken when recovering the state dictionary
of a model (like when using model parallelism).</p>
</dd>
<dt>save_function (<cite>Callable</cite>):</dt><dd><p>The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <cite>torch.save</cite> by another method.</p>
</dd>
<dt>push_to_hub (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):</dt><dd><p>Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <cite>repo_id</cite> (will default to the name of <cite>save_directory</cite> in your
namespace).</p>
</dd>
<dt>max_shard_size (<cite>int</cite> or <cite>str</cite>, <em>optional</em>, defaults to <cite>“5GB”</cite>):</dt><dd><p>The maximum size for a checkpoint before being sharded. Checkpoints shard will then be each of size
lower than this size. If expressed as a string, needs to be digits followed by a unit (like <cite>“5MB”</cite>).
We default it to 5GB in order for models to be able to run easily on free-tier google colab instances
without CPU OOM issues.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>If a single weight of the model is bigger than <cite>max_shard_size</cite>, it will be in its own checkpoint shard
which will be bigger than <cite>max_shard_size</cite>.</p>
<p>&lt;/Tip&gt;</p>
</dd>
<dt>safe_serialization (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>Whether to save the model using <cite>safetensors</cite> or the traditional PyTorch way (that uses <cite>pickle</cite>).</p>
</dd>
<dt>variant (<cite>str</cite>, <em>optional</em>):</dt><dd><p>If specified, weights are saved in the format pytorch_model.&lt;variant&gt;.bin.</p>
</dd>
<dt>token (<cite>str</cite> or <cite>bool</cite>, <em>optional</em>):</dt><dd><p>The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, or not specified, will use
the token generated when running <cite>huggingface-cli login</cite> (stored in <cite>~/.huggingface</cite>).</p>
</dd>
<dt>save_peft_format (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):</dt><dd><p>For backward compatibility with PEFT library, in case adapter weights are attached to the model, all
keys of the state dict of adapters needs to be pre-pended with <cite>base_model.model</cite>. Advanced users can
disable this behaviours by setting <cite>save_peft_format</cite> to <cite>False</cite>.</p>
</dd>
<dt>kwargs (<cite>Dict[str, Any]</cite>, <em>optional</em>):</dt><dd><p>Additional key word arguments passed along to the [<cite>~utils.PushToHubMixin.push_to_hub</cite>] method.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.set_adapter">
<span class="sig-name descname"><span class="pre">set_adapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adapter_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.set_adapter" title="Permalink to this definition"></a></dt>
<dd><p>If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT
official documentation: <a class="reference external" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></p>
<p>Sets a specific adapter by forcing the model to use a that adapter and disable the other adapters.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>adapter_name (<cite>Union[List[str], str]</cite>):</dt><dd><p>The name of the adapter to set. Can be also a list of strings to set multiple adapters.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.set_extra_state" title="Permalink to this definition"></a></dt>
<dd><p>Set extra state contained in the loaded <cite>state_dict</cite>.</p>
<p>This function is called from <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.load_state_dict" title="lambeq.bobcat.BertForChartClassification.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.get_extra_state" title="lambeq.bobcat.BertForChartClassification.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>state (dict): Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.set_input_embeddings">
<span class="sig-name descname"><span class="pre">set_input_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.set_input_embeddings" title="Permalink to this definition"></a></dt>
<dd><p>Set model’s input embeddings.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>value (<cite>nn.Module</cite>): A module mapping vocabulary to hidden states.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.share_memory" title="Permalink to this definition"></a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.state_dict" title="Permalink to this definition"></a></dt>
<dd><p>Return a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>destination (dict, optional): If provided, the state of module will</dt><dd><p>be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</dd>
<dt>prefix (str, optional): a prefix added to parameter and buffer</dt><dd><p>names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p>
</dd>
<dt>keep_vars (bool, optional): by default the <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> s</dt><dd><p>returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>dict:</dt><dd><p>a dictionary containing a whole state of the module</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.supports_gradient_checkpointing">
<span class="sig-name descname"><span class="pre">supports_gradient_checkpointing</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.supports_gradient_checkpointing" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.tie_weights">
<span class="sig-name descname"><span class="pre">tie_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.tie_weights" title="Permalink to this definition"></a></dt>
<dd><p>Tie the weights between the input embeddings and the output embeddings.</p>
<p>If the <cite>torchscript</cite> flag is set in the configuration, can’t handle parameter sharing so we are cloning the
weights instead.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.to" title="Permalink to this definition"></a></dt>
<dd><p>Move and/or cast the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memory_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.channels_last</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Its signature is similar to <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code>, but only accepts
floating point or complex <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.dtype" title="lambeq.bobcat.BertForChartClassification.dtype"><code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code></a>s. In addition, this method will
only cast the floating point or complex parameters and buffers to <a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.dtype" title="lambeq.bobcat.BertForChartClassification.dtype"><code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code></a>
(if given). The integral parameters and buffers will be moved
<a class="reference internal" href="#lambeq.bobcat.BertForChartClassification.device" title="lambeq.bobcat.BertForChartClassification.device"><code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code></a>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>): the desired device of the parameters</dt><dd><p>and buffers in this module</p>
</dd>
<dt>dtype (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>): the desired floating point or complex dtype of</dt><dd><p>the parameters and buffers in this module</p>
</dd>
<dt>tensor (torch.Tensor): Tensor whose dtype and device are the desired</dt><dd><p>dtype and device for all parameters and buffers in this module</p>
</dd>
<dt>memory_format (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.memory_format</span></code>): the desired memory</dt><dd><p>format for 4D parameters and buffers in this module (keyword
only argument)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device=&#39;cuda:1&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
<span class="go">        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="go">tensor([[0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.to_bettertransformer">
<span class="sig-name descname"><span class="pre">to_bettertransformer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">PreTrainedModel</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.to_bettertransformer" title="Permalink to this definition"></a></dt>
<dd><p>Converts the model to use [PyTorch’s native attention
implementation](<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html">https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html</a>), integrated to
Transformers through [Optimum library](<a class="reference external" href="https://huggingface.co/docs/optimum/bettertransformer/overview">https://huggingface.co/docs/optimum/bettertransformer/overview</a>). Only a
subset of all Transformers models are supported.</p>
<p>PyTorch’s attention fastpath allows to speed up inference through kernel fusions and the use of [nested
tensors](<a class="reference external" href="https://pytorch.org/docs/stable/nested.html">https://pytorch.org/docs/stable/nested.html</a>). Detailed benchmarks can be found in [this blog
post](<a class="reference external" href="https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2">https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2</a>).</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>[<cite>PreTrainedModel</cite>]: The model converted to BetterTransformer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.to_empty" title="Permalink to this definition"></a></dt>
<dd><p>Move the parameters and buffers to the specified device without copying storage.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>device (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>): The desired device of the parameters</dt><dd><p>and buffers in this module.</p>
</dd>
<dt>recurse (bool): Whether parameters and buffers of submodules should</dt><dd><p>be recursively moved to the specified device.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.train" title="Permalink to this definition"></a></dt>
<dd><p>Set the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>mode (bool): whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation</dt><dd><p>mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.type" title="Permalink to this definition"></a></dt>
<dd><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><p>dst_type (type or string): the desired type</p>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.warn_if_padding_and_no_attention_mask">
<span class="sig-name descname"><span class="pre">warn_if_padding_and_no_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.warn_if_padding_and_no_attention_mask" title="Permalink to this definition"></a></dt>
<dd><p>Shows a one-time warning if the input_ids appear to contain padding and no attention mask was given.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.xpu" title="Permalink to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>device (int, optional): if specified, all parameters will be</dt><dd><p>copied to that device</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.BertForChartClassification.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.BertForChartClassification.zero_grad" title="Permalink to this definition"></a></dt>
<dd><p>Reset gradients of all model parameters.</p>
<p>See similar function under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>set_to_none (bool): instead of setting to zero, set the grads to None.</dt><dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.Category">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">Category</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atom</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Atom</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Atom.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Feature</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Feature.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Relation</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'\x00'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">argument</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_dep_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/lexicon.html#Category"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Category" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>The type of a constituent in a CCG.</p>
<p>A category may be atomic (e.g. N) or complex (e.g. S/NP).</p>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atom</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Atom</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Atom.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Feature</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Feature.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Relation</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'\x00'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">argument</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_dep_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.Category.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.argument">
<span class="sig-name descname"><span class="pre">argument</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#lambeq.bobcat.Category.argument" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.atom">
<span class="sig-name descname"><span class="pre">atom</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Atom</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Atom.NONE</span></em><a class="headerlink" href="#lambeq.bobcat.Category.atom" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.bwd">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bwd</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.Category.bwd" title="Permalink to this definition"></a></dt>
<dd><p>Whether this is a backward complex category.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.dir">
<span class="sig-name descname"><span class="pre">dir</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'\x00'</span></em><a class="headerlink" href="#lambeq.bobcat.Category.dir" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.feature">
<span class="sig-name descname"><span class="pre">feature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Feature</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Feature.NONE</span></em><a class="headerlink" href="#lambeq.bobcat.Category.feature" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.fwd">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fwd</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.Category.fwd" title="Permalink to this definition"></a></dt>
<dd><p>Whether this is a forward complex category.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.matches">
<span class="sig-name descname"><span class="pre">matches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/lexicon.html#Category.matches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Category.matches" title="Permalink to this definition"></a></dt>
<dd><p>Check if the template set out in this matches the argument.</p>
<p>Like == but the NONE feature matches with everything.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.parse">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_dep_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'+'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.lexicon.Category"><span class="pre">Category</span></a></span></span><a class="reference internal" href="_modules/lambeq/bobcat/lexicon.html#Category.parse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Category.parse" title="Permalink to this definition"></a></dt>
<dd><p>Parse a category string.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.relation">
<span class="sig-name descname"><span class="pre">relation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Relation</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#lambeq.bobcat.Category.relation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.result">
<span class="sig-name descname"><span class="pre">result</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#lambeq.bobcat.Category.result" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.slash">
<span class="sig-name descname"><span class="pre">slash</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">argument</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Relation</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_dep_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a></span></span><a class="reference internal" href="_modules/lambeq/bobcat/lexicon.html#Category.slash"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Category.slash" title="Permalink to this definition"></a></dt>
<dd><p>Create a complex category.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.translate">
<span class="sig-name descname"><span class="pre">translate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">var_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Feature</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Feature.NONE</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.lexicon.Category"><span class="pre">Category</span></a></span></span><a class="reference internal" href="_modules/lambeq/bobcat/lexicon.html#Category.translate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Category.translate" title="Permalink to this definition"></a></dt>
<dd><p>Translate a category.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>var_map</strong><span class="classifier">dict of int to int</span></dt><dd><p>A mapping to relabel variable slots.</p>
</dd>
<dt><strong>feature</strong><span class="classifier">Feature, optional</span></dt><dd><p>The concrete feature for variable features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.type_raising_dep_var">
<span class="sig-name descname"><span class="pre">type_raising_dep_var</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#lambeq.bobcat.Category.type_raising_dep_var" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Category.var">
<span class="sig-name descname"><span class="pre">var</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#lambeq.bobcat.Category.var" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">ChartParser</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grammar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Grammar" title="lambeq.bobcat.Grammar"><span class="pre">Grammar</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root_cats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eisner_normal_form</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_parse_trees</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_tag_score_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing_cat_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing_span_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Sentence" title="lambeq.bobcat.parser.Sentence"><span class="pre">Sentence</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ParseResult</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Parse a sentence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grammar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Grammar" title="lambeq.bobcat.Grammar"><span class="pre">Grammar</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root_cats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eisner_normal_form</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_parse_trees</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_tag_score_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing_cat_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing_span_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.calc_score_binary">
<span class="sig-name descname"><span class="pre">calc_score_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.calc_score_binary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.calc_score_binary" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the score for a binary tree.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.calc_score_unary">
<span class="sig-name descname"><span class="pre">calc_score_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tree</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.calc_score_unary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.calc_score_unary" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the score for a unary tree (chain).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.filter_root">
<span class="sig-name descname"><span class="pre">filter_root</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trees</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">lambeq.bobcat.tree.ParseTree</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">lambeq.bobcat.tree.ParseTree</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.filter_root"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.filter_root" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.get_span_score">
<span class="sig-name descname"><span class="pre">get_span_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">span_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.get_span_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.get_span_score" title="Permalink to this definition"></a></dt>
<dd><p>Get the score in a span for a category (chain) ID.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ChartParser.set_root_cats">
<span class="sig-name descname"><span class="pre">set_root_cats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_cats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.Category"><span class="pre">Category</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#ChartParser.set_root_cats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ChartParser.set_root_cats" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">Grammar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_changing_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/grammar.html#Grammar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Grammar" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>The grammar dataclass.</p>
<dl class="field-list">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>categories</strong><span class="classifier">dict of str to str</span></dt><dd><p>A mapping from a plain category string to a marked up category
string, e.g. ‘(NPNP)/NP’ to ‘((NP{Y}NP{Y}&lt;1&gt;){_}/NP{Z}&lt;2&gt;){_}’</p>
</dd>
<dt><strong>binary_rules: list of tuple of str</strong></dt><dd><p>The list of binary rules as tuple pairs of strings,
e.g. (‘(N/N)’, ‘N’)</p>
</dd>
<dt><strong>type_changing_rules</strong><span class="classifier">list of tuple</span></dt><dd><p>The list of type changing rules, which may occur as either unary
rules or punctuation rules, as tuples of:</p>
<blockquote>
<div><ul class="simple">
<li><p>an integer denoting the rule ID</p></li>
<li><p>a string denoting the left category, or the sole if unary</p></li>
<li><p>a string denoting the right category, or None if unary</p></li>
<li><p>a string denoting the resulting category</p></li>
<li><p>a boolean denoting whether to replace dependencies
during parsing</p></li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>e.g. (1, ‘N’, None, ‘NP’, False)</dt><dd><p>(50, ‘S[dcl]/S[dcl]’, ‘,’, ‘S/S’, True)</p>
</dd>
</dl>
</dd>
<dt><strong>type_raising_rules</strong><span class="classifier">list of tuple</span></dt><dd><dl class="simple">
<dt>The list of type raising rules as tuples of:</dt><dd><ul class="simple">
<li><p>a string denoting the original category</p></li>
<li><p>a string denoting the resulting marked-up category</p></li>
<li><p>a character denoting the new variable</p></li>
</ul>
</dd>
</dl>
<p>e.g. (‘NP’, ‘(S[X]{Y}/(S[X]{Y}NP{_}){Y}){Y}’, ‘+’)</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_changing_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_raising_rules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.Grammar.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.binary_rules">
<span class="sig-name descname"><span class="pre">binary_rules</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Grammar.binary_rules" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.categories">
<span class="sig-name descname"><span class="pre">categories</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Grammar.categories" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">StrPathT</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#lambeq.bobcat.Grammar" title="lambeq.bobcat.Grammar"><span class="pre">Grammar</span></a></span></span><a class="reference internal" href="_modules/lambeq/bobcat/grammar.html#Grammar.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Grammar.load" title="Permalink to this definition"></a></dt>
<dd><p>Load a grammar from a JSON file.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">StrPathT</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/grammar.html#Grammar.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Grammar.save" title="Permalink to this definition"></a></dt>
<dd><p>Save the grammar to a JSON file.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.type_changing_rules">
<span class="sig-name descname"><span class="pre">type_changing_rules</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Grammar.type_changing_rules" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Grammar.type_raising_rules">
<span class="sig-name descname"><span class="pre">type_raising_rules</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Grammar.type_raising_rules" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">ParseTree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Rule'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Category'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">left</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'ParseTree'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">right</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'ParseTree'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unfilled_deps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'list[Dependency]'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filled_deps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'list[Dependency]'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'dict[int,</span> <span class="pre">Variable]'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'float'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/tree.html#ParseTree"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.ParseTree" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Rule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.lexicon.Category"><span class="pre">Category</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">left</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">right</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">unfilled_deps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filled_deps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lambeq.bobcat.tree.Variable</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.ParseTree.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.bwd_comp">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bwd_comp</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.bwd_comp" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.cat">
<span class="sig-name descname"><span class="pre">cat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#lambeq.bobcat.Category" title="lambeq.bobcat.lexicon.Category"><span class="pre">Category</span></a></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.cat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.coordinated">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coordinated</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.coordinated" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.coordinated_or_type_raised">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coordinated_or_type_raised</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.coordinated_or_type_raised" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.deps">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">deps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.deps" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.deps_and_tags">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">deps_and_tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.deps_and_tags" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.filled_deps">
<span class="sig-name descname"><span class="pre">filled_deps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.filled_deps" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.fwd_comp">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fwd_comp</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.fwd_comp" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.is_leaf">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_leaf</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.is_leaf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.left">
<span class="sig-name descname"><span class="pre">left</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.left" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.right">
<span class="sig-name descname"><span class="pre">right</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#lambeq.bobcat.ParseTree" title="lambeq.bobcat.tree.ParseTree"><span class="pre">ParseTree</span></a></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.right" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.rule">
<span class="sig-name descname"><span class="pre">rule</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Rule</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.rule" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.score">
<span class="sig-name descname"><span class="pre">score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.score" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.unfilled_deps">
<span class="sig-name descname"><span class="pre">unfilled_deps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tree.Dependency</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.unfilled_deps" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.var_map">
<span class="sig-name descname"><span class="pre">var_map</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lambeq.bobcat.tree.Variable</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.var_map" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.variable">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">variable</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Variable</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.variable" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lambeq.bobcat.ParseTree.word">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">word</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#lambeq.bobcat.ParseTree.word" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.Sentence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">Sentence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_supertags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.Supertag" title="lambeq.bobcat.parser.Supertag"><span class="pre">lambeq.bobcat.parser.Supertag</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#Sentence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Sentence" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>An input sentence.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>words</strong><span class="classifier">list of str</span></dt><dd><p>The tokens in the sentence.</p>
</dd>
<dt><strong>input_supertags</strong><span class="classifier">list of list of Supertag</span></dt><dd><p>A list of supertags for each word.</p>
</dd>
<dt><strong>span_scores</strong><span class="classifier">dict of tuple of int and int to dict of int to float</span></dt><dd><p>Mapping of a span to a dict of category (indices) mapped to
their log probability.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Sentence.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_supertags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.Supertag" title="lambeq.bobcat.parser.Supertag"><span class="pre">lambeq.bobcat.parser.Supertag</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.Sentence.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Sentence.input_supertags">
<span class="sig-name descname"><span class="pre">input_supertags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#lambeq.bobcat.Supertag" title="lambeq.bobcat.parser.Supertag"><span class="pre">lambeq.bobcat.parser.Supertag</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Sentence.input_supertags" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Sentence.span_scores">
<span class="sig-name descname"><span class="pre">span_scores</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Sentence.span_scores" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Sentence.words">
<span class="sig-name descname"><span class="pre">words</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lambeq.bobcat.Sentence.words" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.Supertag">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">Supertag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">category</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/parser.html#Supertag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Supertag" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A string category, annotated with its log probability.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Supertag.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">category</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#lambeq.bobcat.Supertag.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Supertag.category">
<span class="sig-name descname"><span class="pre">category</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#lambeq.bobcat.Supertag.category" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lambeq.bobcat.Supertag.probability">
<span class="sig-name descname"><span class="pre">probability</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#lambeq.bobcat.Supertag.probability" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lambeq.bobcat.Tagger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lambeq.bobcat.</span></span><span class="sig-name descname"><span class="pre">Tagger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedTokenizerFast</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_prob_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_prob_threshold_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relative'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_prob_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_prob_threshold_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relative'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#Tagger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Tagger" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Tagger.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'progress'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TaggerOutput</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#Tagger.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Tagger.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Parse a list of sentences.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Tagger.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedTokenizerFast</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_prob_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag_prob_threshold_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relative'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_prob_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_prob_threshold_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relative'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#Tagger.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Tagger.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Tagger.parse">
<span class="sig-name descname"><span class="pre">parse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">lambeq.bobcat.tagger.TaggerOutputSentence</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#Tagger.parse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Tagger.parse" title="Permalink to this definition"></a></dt>
<dd><p>Parse a batch of sentences.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lambeq.bobcat.Tagger.prepare_inputs">
<span class="sig-name descname"><span class="pre">prepare_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/lambeq/bobcat/tagger.html#Tagger.prepare_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lambeq.bobcat.Tagger.prepare_inputs" title="Permalink to this definition"></a></dt>
<dd><p>Prepare a batch of sentences for parsing.</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2024 Cambridge Quantum Computing Ltd..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>