<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Step 2. Diagram rewriting" href="rewrite.html" /><link rel="prev" title="References for further study" href="../nlp-refs.html" />

    <link rel="shortcut icon" href="../_static/quantinuum_favicon.svg"/><!-- Generated with Sphinx 6.1.3 and Furo 2024.07.18 -->
        <title>Step 1. Sentence input - lambeq 0.4.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=cf7d2580863ab3a5f2abbe6c31b65acd4d87b848" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=cf727022eb7470bc603c08d2e55c3247faec75c9" />
    <link rel="stylesheet" type="text/css" href="../_static/css/table-wrap.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style>
<link rel="stylesheet" href="../_static/tokens.css"/>
<link rel="stylesheet" href="../_static/styles.css"/>
<link rel="stylesheet" href="../_static/tailwind.css"/>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="preload"
as="style">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
<style>  
  .sidebar-sticky {
    top: calc(3.5rem - 0px);
    height: calc(100vh - 3.5rem);
  }
  
  @media (min-width: 97em) {
    html {
      font-size: 100% !important;
    }
  }
  
</style>
</head>
  <body>
    <script>document.body.setAttribute("data-theme", "light")</script>

    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<nav style="position:fixed;top:0;z-index:1021;width:100%;">
    <div class="nexus-nav"></div>
</nav>
<script type="text/javascript" src="../_static/nav-config.js" ></script>
<script>

  const prefix = "../"
  const isExternalURL = (string) => {
    try {
      return new URL(string).origin !== location.origin;
    } catch (err) {
      console.error(err)
      return false;  
    }
  }
  //

  const resolveLink = (string) => {
    if (isExternalURL(string)) return string
    if (string.startsWith("/")) {
      string = string.slice(1)
    }
    if (prefix === "#") {
      return string;
    }
    return prefix + string;
  
  }
  const navTextLinks = navConfig.navTextLinks.map(x => ({
    ...x,
    href: resolveLink(x.href),
  }));
   const navProductName = navConfig.navProductName;
  const navIconLinks = navConfig.navIconLinks.map(x => {
    return {...x,
    href: resolveLink(x.href),
    iconImageURL: resolveLink(x.iconImageURL),
  }}
  
  );

</script>
<script type="text/javascript" src="../_static/index.global.js"></script>



<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">lambeq 0.4.2 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/lambeq_logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">lambeq 0.4.2 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parsing.html">Syntactic parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../string-diagrams.html">String diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use-cases.html">lambeq use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing to lambeq</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NLP-101</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nlp-intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp-data.html">Working with text data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp-class.html">Text classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp-ml.html">Machine learning best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp-refs.html">References for further study</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Step 1. Sentence input</a></li>
<li class="toctree-l1"><a class="reference internal" href="rewrite.html">Step 2. Diagram rewriting</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameterise.html">Step 3. Parameterisation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../training.html">Step 4: Training</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Step 4: Training</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="trainer-classical.html">Training: Classical case</a></li>
<li class="toctree-l2"><a class="reference internal" href="trainer-quantum.html">Training: Quantum case</a></li>
<li class="toctree-l2"><a class="reference internal" href="trainer-hybrid.html">Training: Hybrid case</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Choosing a model</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../manual-training.html">Advanced: Manual training</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Advanced: Manual training</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="training-symbols.html">Introduction to symbols</a></li>
<li class="toctree-l2"><a class="reference internal" href="training-usecase.html">A complete use case</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../advanced.html">Advanced: low-level lambeq</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Advanced: low-level lambeq</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="monoidal.html">Monoidal categories in lambeq</a></li>
<li class="toctree-l2"><a class="reference internal" href="discocat.html">DisCoCat in lambeq</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extend-lambeq.html">Advanced: Extending lambeq</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/tokenisation.html">Tokenisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/unk-words.html">Handling unknown words</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/parser.html">Parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/reader.html">Reader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/tree-reader.html">Tree reader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/rewrite.html">Rewrite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/circuit.html">Circuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/tensor.html">Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/rotosolve-optimizer.html">Rotosolve optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/classical-pipeline.html">Classical pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/quantum-pipeline.html">Quantum pipeline using the Quantum Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/quantum-pipeline-jax.html">Quantum pipeline using JAX backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/pennylane.html">Training hybrid models using the Pennylane backend</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Toolkit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../root-api.html">lambeq package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../package-api.html">Subpackages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uml-diagrams.html">Class diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-line interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">Release notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">External links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/downloads.html">Resources</a></li>
<li class="toctree-l1"><a class="reference external" href="https://qnlp.cambridgequantum.com/generate.html">Web demo</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discopy.readthedocs.io">DisCoPy</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/tutorials/sentence-input.ipynb.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Step-1.-Sentence-input">
<h1>Step 1. Sentence input<a class="headerlink" href="#Step-1.-Sentence-input" title="Permalink to this heading">¶</a></h1>
<p>The first part of the process in <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> given a sentence, is to convert it into a <a class="reference internal" href="../glossary.html#term-string-diagram"><span class="xref std std-term">string diagram</span></a>, according to a given <a class="reference internal" href="../glossary.html#term-compositional-model"><span class="xref std std-term">compositional scheme</span></a>. <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> can accommodate any <a class="reference internal" href="../glossary.html#term-compositional-model"><span class="xref std std-term">compositional model</span></a> that can encode sentences as <a class="reference internal" href="../glossary.html#term-string-diagram"><span class="xref std std-term">string diagrams</span></a>, its native data structure. The toolkit currently includes a number of <a class="reference internal" href="../glossary.html#term-compositional-model"><span class="xref std std-term">compositional models</span></a>, using various degrees of syntactic information: <a class="reference internal" href="../glossary.html#term-bag-of-words"><span class="xref std std-term">bag-of-words</span></a> models do not use any syntactic information, <a class="reference internal" href="../glossary.html#term-word-sequence-model"><span class="xref std std-term">word-sequence models</span></a> respect the order of words, while fully syntax-based models are based on grammatical derivations provided by a parser.</p>
<p><a class="reference download internal" download="" href="../_downloads/5654da6976a7b7b8e5bbe958b8a05822/sentence-input.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">code</span></code></a></p>
<section id="Pre-processing-and-tokenisation">
<h2>Pre-processing and tokenisation<a class="headerlink" href="#Pre-processing-and-tokenisation" title="Permalink to this heading">¶</a></h2>
<p>Depending on the form of your data, some preprocessing steps may be required to make it appropriate for <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> use. Section <a class="reference internal" href="../nlp-data.html#sec-preprocessing"><span class="std std-ref">Text pre-processing</span></a> in the <a class="reference internal" href="../nlp-intro.html#sec-nlp-intro"><span class="std std-ref">NLP-101 tutorial</span></a> provides more information about this. Here we will mainly talk about <a class="reference internal" href="../nlp-data.html#sec-tokenization"><span class="std std-ref">tokenisation</span></a>, which is crucial in getting correct derivations from the <a class="reference internal" href="../glossary.html#term-Bobcat"><span class="xref std std-term">Bobcat</span></a> parser.</p>
<p>The term <cite>tokenisation</cite> refers to the process of breaking down a text or sentence into smaller units called <cite>tokens</cite>. In <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> these tokens correspond to words, since the parser needs to know exactly what kind of words or symbols and punctuation marks are included in the sentence in order to provide an accurate grammatical analysis.</p>
<p>By default, Bobcat parser assumes that every sentence is delimited by a whitespace, as below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;John gave Mary a flower&quot;</span>
</pre></div>
</div>
<p>Note however that when working with raw text, this is rarely the case. Consider for example the sentence:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;This sentence isn&#39;t worth £100 (or is it?).&quot;</span>
</pre></div>
</div>
<p>A naïve tokenisation based on white spaces would result in the following list of tokens:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[&quot;This&quot;, &quot;sentence&quot;, &quot;isn&#39;t&quot;, &quot;worth&quot;, &quot;£100&quot;, &quot;(or&quot;, &quot;is&quot;, &quot;it?).&quot;]</span>
</pre></div>
</div>
<p>missing, for example, that “isn’t” represents actually two words and “(or” is not a proper word.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">lambeq</span></code>, tokenisation is provided through the <a class="reference internal" href="../lambeq.tokeniser.html#lambeq.tokeniser.Tokeniser" title="lambeq.tokeniser.Tokeniser"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tokeniser</span></code></a> class hierarcy, and specifically by using the <a class="reference internal" href="../lambeq.tokeniser.html#lambeq.tokeniser.SpacyTokeniser" title="lambeq.tokeniser.SpacyTokeniser"><code class="xref py py-class docutils literal notranslate"><span class="pre">SpacyTokeniser</span></code></a> class, based on the popular NLP package <a class="reference external" href="https://spacy.io">SpaCy</a>. Here is an example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">SpacyTokeniser</span>

<span class="n">tokeniser</span> <span class="o">=</span> <span class="n">SpacyTokeniser</span><span class="p">()</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;This sentence isn&#39;t worth £100 (or is it?).&quot;</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokeniser</span><span class="o">.</span><span class="n">tokenise_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="n">tokens</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;This&#39;,
 &#39;sentence&#39;,
 &#39;is&#39;,
 &#34;n&#39;t&#34;,
 &#39;worth&#39;,
 &#39;£&#39;,
 &#39;100&#39;,
 &#39;(&#39;,
 &#39;or&#39;,
 &#39;is&#39;,
 &#39;it&#39;,
 &#39;?&#39;,
 &#39;)&#39;,
 &#39;.&#39;]
</pre></div></div>
</div>
<p>We can then pass the list of the tokens to the parser, setting the <code class="docutils literal notranslate"><span class="pre">tokenised</span></code> argument of the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.BobcatParser.sentence2diagram" title="lambeq.text2diagram.BobcatParser.sentence2diagram"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sentence2diagram()</span></code></a> method to True.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">BobcatParser</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">BobcatParser</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;suppress&#39;</span><span class="p">)</span>
<span class="n">diagram</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tokenised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_6_0.png" src="../_images/tutorials_sentence-input_6_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More details about <a class="reference internal" href="../glossary.html#term-DisCoCat"><span class="xref std std-term">DisCoCat</span></a> and syntax-based models will follow below.</p>
</div>
<p>To tokenise many sentences at once, use the <a class="reference internal" href="../lambeq.tokeniser.html#lambeq.tokeniser.SpacyTokeniser.tokenise_sentences" title="lambeq.tokeniser.SpacyTokeniser.tokenise_sentences"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tokenise_sentences()</span></code></a> method:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;This is a sentence.&quot;</span><span class="p">,</span> <span class="s2">&quot;This is (another) sentence!&quot;</span><span class="p">]</span>

<span class="n">tok_sentences</span> <span class="o">=</span> <span class="n">tokeniser</span><span class="o">.</span><span class="n">tokenise_sentences</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">tok_sentences</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[&#39;This&#39;, &#39;is&#39;, &#39;a&#39;, &#39;sentence&#39;, &#39;.&#39;],
 [&#39;This&#39;, &#39;is&#39;, &#39;(&#39;, &#39;another&#39;, &#39;)&#39;, &#39;sentence&#39;, &#39;!&#39;]]
</pre></div></div>
</div>
<p>Finally, <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> provides tokenisation at the sentence-level:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;I love pizza. It is my favorite food. I could eat it every day!&quot;</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">tokeniser</span><span class="o">.</span><span class="n">split_sentences</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">sentences</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;I love pizza.&#39;, &#39;It is my favorite food.&#39;, &#39;I could eat it every day!&#39;]
</pre></div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To simplify the rest of this tutorial, all sentences in the following sections will be delimited by white spaces, so that the parser can tokenise them properly without extra handling.</p>
</div>
</section>
<section id="Syntax-based-model:-DisCoCat">
<h2>Syntax-based model: DisCoCat<a class="headerlink" href="#Syntax-based-model:-DisCoCat" title="Permalink to this heading">¶</a></h2>
<p>In order to obtain a <a class="reference internal" href="../glossary.html#term-DisCoCat"><span class="xref std std-term">DisCoCat</span></a>-like output, we first use the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.BobcatParser" title="lambeq.text2diagram.BobcatParser"><code class="xref py py-class docutils literal notranslate"><span class="pre">BobcatParser</span></code></a> class from <a class="reference internal" href="../lambeq.text2diagram.html#module-lambeq.text2diagram" title="lambeq.text2diagram"><code class="xref py py-mod docutils literal notranslate"><span class="pre">text2diagram</span></code></a> package, which, in turn,  calls the <a class="reference internal" href="../glossary.html#term-parser"><span class="xref std std-term">parser</span></a>, obtains a <a class="reference internal" href="../glossary.html#term-Combinatory-Categorial-Grammar-CCG"><span class="xref std std-term">CCG</span></a> derivation for the sentence, and converts it into a <a class="reference internal" href="../glossary.html#term-string-diagram"><span class="xref std std-term">string diagram</span></a>. The code below uses the default <a class="reference internal" href="../glossary.html#term-Bobcat"><span class="xref std std-term">Bobcat</span></a> parser in order to produce a <a class="reference internal" href="../glossary.html#term-string-diagram"><span class="xref std std-term">string diagram</span></a> for the sentence “John walks in the park”.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">lambeq</span></code>’s string diagrams are objects of the class <a class="reference internal" href="../lambeq.backend.html#lambeq.backend.grammar.Diagram" title="lambeq.backend.grammar.Diagram"><code class="xref py py-class docutils literal notranslate"><span class="pre">lambeq.backend.grammar.Diagram</span></code></a>.</p>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">BobcatParser</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="s1">&#39;John walks in the park&#39;</span>

<span class="c1"># Parse the sentence and convert it into a string diagram</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">BobcatParser</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;suppress&#39;</span><span class="p">)</span>
<span class="n">diagram</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="n">diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_14_0.png" src="../_images/tutorials_sentence-input_14_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Recall from previous section that when the input to <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.BobcatParser.sentence2diagram" title="lambeq.text2diagram.BobcatParser.sentence2diagram"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sentence2diagram()</span></code></a> method is a list of tokens, you should also set <code class="docutils literal notranslate"><span class="pre">tokenised</span></code> argument to True (by default is set to False).</p>
</div>
<p>Another case of syntax-based models in <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> is <a class="reference internal" href="#sec-tree-readers"><span class="std std-ref">tree readers</span></a>, which will be presented later in this tutorial.</p>
</section>
<section id="Bag-of-words:-Spiders-reader">
<h2>Bag-of-words: Spiders reader<a class="headerlink" href="#Bag-of-words:-Spiders-reader" title="Permalink to this heading">¶</a></h2>
<p><a class="reference internal" href="../glossary.html#term-DisCoCat"><span class="xref std std-term">DisCoCat</span></a> is not the only <a class="reference internal" href="../glossary.html#term-compositional-model"><span class="xref std std-term">compositional model</span></a> that <code class="docutils literal notranslate"><span class="pre">lambeq</span></code> supports. In fact, any compositional scheme that manifests sentences as <a class="reference internal" href="../glossary.html#term-string-diagram"><span class="xref std std-term">string diagrams</span></a>/<a class="reference internal" href="../glossary.html#term-tensor-network"><span class="xref std std-term">tensor networks</span></a> can be added to the toolkit via the readers of the <a class="reference internal" href="../lambeq.text2diagram.html#module-lambeq.text2diagram" title="lambeq.text2diagram"><code class="xref py py-mod docutils literal notranslate"><span class="pre">text2diagram</span></code></a> package. For example, the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.spiders_reader" title="lambeq.text2diagram.spiders_reader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spiders_reader</span></code></a> object of the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.LinearReader" title="lambeq.text2diagram.LinearReader"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearReader</span></code></a> class represents a sentence as a “<a class="reference internal" href="../glossary.html#term-bag-of-words"><span class="xref std std-term">bag-of-words</span></a>”, composing the words using a <a class="reference internal" href="../glossary.html#term-spider"><span class="xref std std-term">spider</span></a> (a commutative operation).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">spiders_reader</span>

<span class="c1"># Create string diagrams based on spiders reader</span>
<span class="n">spiders_diagram</span> <span class="o">=</span> <span class="n">spiders_reader</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="c1"># Not a pregroup diagram, we can&#39;t use grammar.draw()</span>
<span class="n">spiders_diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_18_0.png" src="../_images/tutorials_sentence-input_18_0.png" />
</div>
</div>
</section>
<section id="Word-sequence-models:-Cups-and-stairs-readers">
<h2>Word-sequence models: Cups and stairs readers<a class="headerlink" href="#Word-sequence-models:-Cups-and-stairs-readers" title="Permalink to this heading">¶</a></h2>
<p>The <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.LinearReader" title="lambeq.text2diagram.LinearReader"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearReader</span></code></a> class can be used to create any kind of model where words are composed in sequence, from left to right. For example, the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.cups_reader" title="lambeq.text2diagram.cups_reader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cups_reader</span></code></a> instance of this class generates a “<a class="reference internal" href="../glossary.html#term-tensor-train"><span class="xref std std-term">tensor train</span></a>”.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">cups_reader</span>

<span class="c1"># Create string diagrams based on cups reader</span>
<span class="n">cups_diagram</span> <span class="o">=</span> <span class="n">cups_reader</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="n">cups_diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_21_0.png" src="../_images/tutorials_sentence-input_21_0.png" />
</div>
</div>
<p>Note the use of a <code class="docutils literal notranslate"><span class="pre">START</span></code> symbol in the beginning of the sentence, represented as an order-1 tensor (a vector). This ensures that the final result of the computation (that is, the representation of the sentence) will be again a tensor of order 1.</p>
<p>Another pre-made word-sequence model is provided by the <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.stairs_reader" title="lambeq.text2diagram.stairs_reader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stairs_reader</span></code></a> instance. This model combines consecutive words using a box (“cell”) in a recurrent fashion, similarly to a recurrent neural network.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">stairs_reader</span>

<span class="n">stairs_diagram</span> <span class="o">=</span> <span class="n">stairs_reader</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="n">stairs_diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_24_0.png" src="../_images/tutorials_sentence-input_24_0.png" />
</div>
</div>
<span class="target" id="sec-tree-readers"></span></section>
<section id="Tree-readers">
<h2>Tree readers<a class="headerlink" href="#Tree-readers" title="Permalink to this heading">¶</a></h2>
<p>A <a class="reference internal" href="../glossary.html#term-Combinatory-Categorial-Grammar-CCG"><span class="xref std std-term">CCG</span></a> derivation follows a biclosed form <a class="reference internal" href="../bibliography.html#yk2021" id="id1"><span>[YK2021]</span></a> , which can be directly interpreted as a series of compositions without any explicit conversion into a <a class="reference internal" href="../glossary.html#term-pregroup-grammar"><span class="xref std std-term">pregroup</span></a> form. Class <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.TreeReader" title="lambeq.text2diagram.TreeReader"><code class="xref py py-class docutils literal notranslate"><span class="pre">TreeReader</span></code></a> implements a number of compositional models by taking advantage of this fact. In order to demonstrate the way they work, it would be useful to first examine how a CCG diagram looks like:</p>
<center><p><img alt="4f0e8d2017704ea09925a8fe1c1ca963" class="no-scaled-link" src="../_images/ccg-diagram.png" style="width: 350px;" /></p>
</center><p>Even without knowing the specifics of CCG syntax, it is not difficult to see that the verb “gave” is first composed with the indirect object “Mary”, then the result is composed with the noun phrase “a flower” which correspond to the direct object, and finally the entire verb phrase “gave Mary a flower” is further composed with the subject “John” to return a sentence. A <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.TreeReader" title="lambeq.text2diagram.TreeReader"><code class="xref py py-class docutils literal notranslate"><span class="pre">TreeReader</span></code></a> follows this order of composition, as demonstrated below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">TreeReader</span>

<span class="n">reader</span> <span class="o">=</span> <span class="n">TreeReader</span><span class="p">()</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;John gave Mary a flower&quot;</span>

<span class="n">tree_diagram</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="n">tree_diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_30_0.png" src="../_images/tutorials_sentence-input_30_0.png" />
</div>
</div>
<p>Note that in this default call, composition is handled by a single “cell” named <code class="docutils literal notranslate"><span class="pre">UNIBOX</span></code>. This can be changed by passing an explicit argument of type <a class="reference internal" href="../lambeq.text2diagram.html#lambeq.text2diagram.TreeReaderMode" title="lambeq.text2diagram.TreeReaderMode"><code class="xref py py-class docutils literal notranslate"><span class="pre">TreeReaderMode</span></code></a> to the reader’s constructor. There are three possible choices:</p>
<ul class="simple">
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">NO_TYPE</span></code> is the default, where all compositions are handled by the same <code class="docutils literal notranslate"><span class="pre">UNIBOX</span></code> cell (above diagram).</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">RULE_ONLY</span></code> creates a different cell for each CCG rule.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">RULE_TYPE</span></code> creates a different cell for each (rule, type) pair.</p></li>
</ul>
<p>For example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lambeq</span> <span class="kn">import</span> <span class="n">TreeReader</span><span class="p">,</span> <span class="n">TreeReaderMode</span>

<span class="n">reader</span> <span class="o">=</span> <span class="n">TreeReader</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">TreeReaderMode</span><span class="o">.</span><span class="n">RULE_ONLY</span><span class="p">)</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;John gave Mary a flower&quot;</span>

<span class="n">tree_diagram</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">sentence2diagram</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="n">tree_diagram</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_sentence-input_32_0.png" src="../_images/tutorials_sentence-input_32_0.png" />
</div>
</div>
<p>In the above, each unique CCG rule gets its own box: FA boxes correspond to forward application, and BA boxes to backward application. For certain tasks, making the composition box rule-specific might lead to better generalisation and overall performance.</p>
<p class="rubric">See also:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../nlp-data.html#sec-preprocessing"><span class="std std-ref">Text pre-processing</span></a></p></li>
<li><p><a class="reference internal" href="../package-api.html#api-text2diagram"><span class="std std-ref">lambeq.text2diagram package</span></a></p></li>
<li><p><a class="reference internal" href="../examples/parser.html"><span class="doc">Example notebook parser.ipynb</span></a></p></li>
<li><p><a class="reference internal" href="../examples/reader.html"><span class="doc">Example notebook reader.ipynb</span></a></p></li>
<li><p><a class="reference internal" href="../examples/tree-reader.html"><span class="doc">Example notebook tree-reader.ipynb</span></a></p></li>
<li><p><a class="reference internal" href="discocat.html"><span class="doc">DisCoCat in lambeq</span></a></p></li>
<li><p><a class="reference internal" href="extend-lambeq.html"><span class="doc">Extending lambeq</span></a></p></li>
</ul>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="rewrite.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Step 2. Diagram rewriting</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../nlp-refs.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">References for further study</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021-2024 Cambridge Quantum Computing Ltd.
            </div>
            <div class="terms" style="display:flex; gap:0.5rem; align-items:center; margin: 0.25rem 0rem;">
              <a href="https://www.quantinuum.com/privacy-statement" target="_blank">Privacy Statement</a>
              <div role="separator">/</div>
              <a href="https://www.quantinuum.com/cookie-notice" target="_blank">Cookie Notice</a>
              <div role="separator">/</div>
              <a href="https://www.quantinuum.com/terms-conditions" target="_blank">Terms and Conditions</a>
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Step 1. Sentence input</a><ul>
<li><a class="reference internal" href="#Pre-processing-and-tokenisation">Pre-processing and tokenisation</a></li>
<li><a class="reference internal" href="#Syntax-based-model:-DisCoCat">Syntax-based model: DisCoCat</a></li>
<li><a class="reference internal" href="#Bag-of-words:-Spiders-reader">Bag-of-words: Spiders reader</a></li>
<li><a class="reference internal" href="#Word-sequence-models:-Cups-and-stairs-readers">Word-sequence models: Cups and stairs readers</a></li>
<li><a class="reference internal" href="#Tree-readers">Tree readers</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div>
<script>document.body.setAttribute("data-theme", "light")</script><script src="../_static/jquery.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>